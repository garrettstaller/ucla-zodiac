{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a54a383-cb59-4c3a-8f9f-f008d196fdb5",
   "metadata": {},
   "source": [
    "# Satellite Data \n",
    "\n",
    "**How to use script:**\n",
    "1. **Specify desired date**\n",
    "   - Date Format *1*: `day/month/year`  --> 290515 for May 29th 2015\n",
    "   - Date Format *2*: `year/month/day`  --> 20150529 for May 29th 2015 <p>\n",
    "\n",
    "2. **Directories with SoCal Coastal Relief Map and GPS data**\n",
    "   - Link for GPS data: http://wimsoft.com/CAL/files/\n",
    "   - Link for SoCal data: https://www.geoplatform.gov/metadata/1f9d35ae-ef0b-43c8-8657-e0de4c55a7e8\n",
    "  \n",
    "**GPS Data is required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b46f9-7e52-4981-95a8-81b526548e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Edit Code HERE ----- #\n",
    "date = '20150529'\n",
    "\n",
    "# Location of depth data\n",
    "fname = './crm_socal_1as_vers2.nc'\n",
    "\n",
    "# Location of GPS data for Sat Data\n",
    "gps_filename = './cal_aco_3840_Latitude_Longitude.hdf'\n",
    "\n",
    "# Parameters #\n",
    "window_size = 25\n",
    "\n",
    "# Treating Data #\n",
    "rmv_nan = True\n",
    "rmv_mdr = False\n",
    "\n",
    "# Plotting (temp files) #\n",
    "# cruise track \n",
    "plot_track = True\n",
    "# bathymetry\n",
    "plot_bath  = True\n",
    "# land features\n",
    "plot_land  = True\n",
    "\n",
    "# Save options #\n",
    "saveplots = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47baf4-3375-4ab7-9eaa-591d24b0f93e",
   "metadata": {},
   "source": [
    "#### Employed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37221cfa-f97c-4033-aff7-6630294b4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# satellite data upload\n",
    "import requests \n",
    "import tempfile\n",
    "import tables\n",
    "from io import BytesIO\n",
    "import os\n",
    "# Functions \n",
    "import pyhdf as hp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyhdf.SD import SD, SDC\n",
    "# Zodiac data\n",
    "import pickle\n",
    "import functions as zf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f562825-a7d8-42d4-9612-05d2751bf07b",
   "metadata": {},
   "source": [
    "### Pre Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9209bb13-158f-4810-98a9-077167f38445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- GPS DATA ------- #\n",
    "\n",
    "# Open the HDF4 file in read mode\n",
    "hdf_file = SD(gps_filename, SDC.READ)\n",
    "\n",
    "# List all available datasets in the HDF4 file\n",
    "datasets = hdf_file.datasets()\n",
    "\n",
    "# Access a specific dataset (replace 'dataset_name' with actual dataset name)\n",
    "lat_dataset = hdf_file.select('Latitude')\n",
    "lon_dataset = hdf_file.select('Longitude')\n",
    "\n",
    "# Read data from the selected dataset\n",
    "lat = lat_dataset.get()\n",
    "lon = lon_dataset.get()\n",
    "\n",
    "# Bound and set 1D arrays for colormesh plotting \n",
    "lat  = lat[1350:1410,1780:1885]\n",
    "lon  = lon[1350:1410,1780:1885]\n",
    "longitude = np.linspace(np.min(lon), np.max(lon), lon.shape[1])\n",
    "latitude = np.linspace(np.min(lat), np.max(lat), len(lat))\n",
    "\n",
    "# Close the HDF4 file after use\n",
    "hdf_file.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c5f0e-6785-4160-99f7-aeb75141af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Depth/Land DATA ------- #\n",
    "\n",
    "if plot_land and plot_bath:\n",
    "\n",
    "    from netCDF4 import Dataset, num2date\n",
    "    \n",
    "    nc = Dataset(fname)\n",
    "    \n",
    "    res = 2\n",
    "    \n",
    "    lon, lat = np.array(nc.variables['lon'][::res]), np.array(nc.variables['lat'][::res])\n",
    "    depths = np.array(nc.variables['Band1'][::res, ::res])\n",
    "    \n",
    "    lon_min = np.where((lon <= -118.25) & (lon > -118.85))[0][-1]\n",
    "    lon_max = np.where((lon <= -118.25) & (lon > -118.85))[0][0]\n",
    "    lat_min = np.where((lat >= 33.5) & (lat < 34.15))[0][0]\n",
    "    lat_max = np.where((lat >= 33.5) & (lat < 34.15))[0][-1]\n",
    "    \n",
    "    depths = depths[lat_min:lat_max, lon_max:lon_min]\n",
    "    \n",
    "    lon_bath    = lon[lon_max:lon_min]\n",
    "    lat_bath    = lat[lat_min:lat_max]\n",
    "    \n",
    "    lon_bath, lat_bath = np.meshgrid(lon_bath, lat_bath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d897cbe-cb7c-48ee-b2c8-c55fbd7efced",
   "metadata": {},
   "source": [
    "### 1. Individual Cruise w/ Satellite Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224f836-c610-4003-8245-02a69e5ddcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Cruise DATA ------- #\n",
    "\n",
    "with open('track_data.pkl', 'rb') as ztd:\n",
    "    zodiac_track_data = pickle.load(ztd)\n",
    "\n",
    "try:\n",
    "    # FUNCTION WILL GRAB DICTIONARY WITH CORREPSONDING DATE AND REMOVE NANS AS WELL AS ENSURE DATA IS IN DEFINED BOUNDS OF SMB - EXCLUDING MARINA\n",
    "    lat, lon, SST, flu = zf.select_track(date, zodiac_track_data, excludenans=rmv_nan, excludemdr=rmv_mdr)\n",
    "    print('Cruise data found')\n",
    "    # Data Processing, Filtering, & Gradients for SST #\n",
    "    dist_processed, sst_processed = zf.data_processing(lat, lon, SST, 10)\n",
    "    grad_dist_sst, grad_sst, lat_sst, lon_sst, sst_filtered, dist_filtered = \\\n",
    "    zf.running_avg_filter(window_size, lat, lon, sst_processed, dist_processed)\n",
    "    print('SST filtered...')\n",
    "    # Data Processing, Filtering, & Gradients for Flu #\n",
    "    dist_processed, flu_processed = zf.data_processing(lat, lon, flu, 10)\n",
    "    grad_dist_flu, grad_flu, grad_lat_flu, grad_lon_flu, flu_filtered, dist_filtered = \\\n",
    "    zf.running_avg_filter(window_size, lat, lon, flu_processed, dist_processed)\n",
    "    print('Flu filtered...')\n",
    "except:\n",
    "    plot_track = False\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a8720-4795-4f15-ae83-c96ecc21cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Generate URL ------- #\n",
    "\n",
    "# from date, determine day of year \n",
    "days_in_month = [31, 60, 91, 120, 151, 181, 212, 243, 273, 304, 334, 365]\n",
    "\n",
    "if len(date) == 6:\n",
    "    year  = str(int(date[4:6]) + 2000)\n",
    "    month = date[2:4]\n",
    "    day   = date[0:2]\n",
    "else:\n",
    "    year  = date[0:4]\n",
    "    month = date[4:6]\n",
    "    day   = date[6:9]\n",
    "\n",
    "if (int(year) % 4) == 0:\n",
    "    leap_year = 1\n",
    "else:\n",
    "    leap_year = 0\n",
    "\n",
    "if int(month) != 1:\n",
    "    day_of_year = str(days_in_month[np.abs(int(month) - 2)] + int(day) + leap_year)\n",
    "else:\n",
    "    day_of_year = str(int(day) + leap_year)\n",
    "\n",
    "print(year, month, day, day_of_year)\n",
    "\n",
    "# url \n",
    "url = f\"https://spg-satdata.ucsd.edu/{year}/M{year}_{type}_day/M{year}{day_of_year}_{type}_comp.hdf\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49f7d9-52d7-4bf5-b994-6a9eb127551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Temporaray File Load and Plotting ------- #\n",
    "\n",
    "# Step 1: Download the HDF4 file using requests\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    print(\"File downloaded successfully!\")\n",
    "\n",
    "# Step 2: Create a temporary file to save the HDF4 content\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "        tmp_file.write(response.content)  # Write the downloaded file content to the temp file\n",
    "        tmp_file_path = tmp_file.name     # Get the path to the temporary file\n",
    "\n",
    "    print(f\"File saved temporarily at: {tmp_file_path}\", end = '\\r')\n",
    "\n",
    "    # Step 3: Open the HDF4 file from the temporary file using PyHDF\n",
    "    try:\n",
    "        hdf_file = SD(tmp_file_path, SDC.READ)\n",
    "\n",
    "        # List all datasets in the file\n",
    "        print(\"Datasets in the file:\")\n",
    "        datasets = hdf_file.datasets()\n",
    "        for dataset_name in datasets:\n",
    "            print(f\"- {dataset_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening HDF file: {e}\")\n",
    "\n",
    "    # Step 4: Grab data and close file\n",
    "    dataset = hdf_file.select(dataset_name)\n",
    "    # Read data from the selected dataset\n",
    "    data = dataset.get()\n",
    "    print(\"Shape of data:\", data.shape)\n",
    "    # Close the HDF4 file after use\n",
    "    hdf_file.end()\n",
    "\n",
    "    # Step 5: Adjust from pixel values to SST\n",
    "    data = data.astype(np.int16)\n",
    "    # Bound to SoCal - based on indices of pixel values\n",
    "    data = data[1350:1410,1780:1885]\n",
    "    # Add 256 to negative values\n",
    "    data[data < 0] += 256\n",
    "    # Exclude pixel boundary values\n",
    "    data[(data == 0) | (data == 255)] = 0\n",
    "    # Adjust pixels to SST\n",
    "    SST = (.15*data) - 3.0\n",
    "    SST[SST == np.max(SST)] = 0\n",
    "\n",
    "    # --- PLOTTING ---\n",
    "    fig1 = plt.figure(1, (20,15))\n",
    "    # Satellite Data\n",
    "    if plot_track:\n",
    "        sat = plt.pcolormesh(longitude, latitude[::-1], SST, cmap = 'jet', vmin = np.min(sst_filtered), vmax = np.max(sst_filtered))\n",
    "    else:\n",
    "        sat = plt.pcolormesh(longitude, latitude[::-1], SST, cmap = 'jet', vmin = np.min(SST[SST>0]), vmax = np.max(SST[SST>0]))\n",
    "    cbar = plt.colorbar()\n",
    "    if plot_track:\n",
    "        cbar.set_label('SST - Bins are Daily Avg. at 1km Res. / Track at 10m Res.', fontsize = 25)\n",
    "    else:\n",
    "        cbar.set_label('SST - Bins are Daily Avg. at 1km Res.', fontsize = 25)\n",
    "    cbar.ax.tick_params(labelsize = 20)\n",
    "\n",
    "    if plot_track:\n",
    "        # Cruise Track \n",
    "        plt.scatter(lon_sst, lat_sst, c = sst_filtered, cmap='jet', vmin=np.min(sst_filtered), vmax = np.max(sst_filtered))\n",
    "\n",
    "    if plot_bath:\n",
    "        # Bathymetric Contouts\n",
    "        bathy = plt.contour(lon_bath, lat_bath, depths, [-800, -600, -400, -200, -100, -50, -25, -10], cmap='bone', vmin=-10, alpha = .8)\n",
    "        plt.clabel(bathy, inline = True, fontsize = 14)\n",
    "\n",
    "    if plot_land:\n",
    "        # Land Features\n",
    "        terra = plt.scatter(lon_bath[depths > 0], lat_bath[depths > 0], c = depths[depths > 0], cmap = 'gist_earth', vmin = 10)\n",
    "        terra.set_clim(-500)\n",
    "        # Add locations\n",
    "        fs_label = 20\n",
    "        plt.text(-118.81, 34.01, 'Point \\nDume', fontsize=fs_label, rotation=-40, ha='center', color = 'white')\n",
    "        plt.text(-118.67, 34.04, 'Malibu', fontsize=fs_label, rotation=0, ha='center', color = 'white')\n",
    "        plt.text(-118.47, 34.0,  'Santa Monica', fontsize=fs_label, rotation=  0, ha='left',   color = 'white')\n",
    "        plt.text(-118.41, 33.85,  'Redondo \\n Beach', fontsize=fs_label, rotation=0, ha='left',color = 'white')\n",
    "        plt.text(-118.345, 33.735, 'Palos Verdes', fontsize=fs_label, rotation=-20, ha='center', color = 'white')\n",
    "        \n",
    "    # Bounds\n",
    "    plt.ylim(33.65, 34.05)\n",
    "    plt.xlim(-118.85, -118.25)\n",
    "    \n",
    "    # Ticks\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "\n",
    "    # Labeling \n",
    "    plt.title(f'Satellite View of SST for {month}/{day}/{year}', fontsize = 30)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    # --- PLOTTING ---\n",
    "\n",
    "    # Step 6: Clean up by removing the temporary file (optional)\n",
    "    if os.path.exists(tmp_file_path):\n",
    "        os.remove(tmp_file_path)\n",
    "        print(f\"Temporary file {tmp_file_path} removed.\", end = '\\r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46a607-2589-499d-a79e-45aad4336cd4",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d41005-0d07-44dc-b074-c6a7fd379a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
