{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f83b5b-596f-4514-80bd-314e30c699ed",
   "metadata": {},
   "source": [
    "## *<font color = maroon> Notebook 2: </font>* Detection of Sea Surface Temperature (SST) Filaments and Fronts - \n",
    "**This script includes the following:** <br> \n",
    "1. **Automated Detection**<br>\n",
    "    - **Filaments** - *A parabolic dip in SST, where SST transitions sharply like a front, but with two sides and cool water in the middle*\n",
    "        - Continous track - no gaps in data larger than 50 meters - has local minima in SST \n",
    "        - A SST gradient exceeding user set <font color = magenta> threshold </font>\n",
    "        - Boat heading does not change more than 90$^{\\circ}$ in structure\n",
    "        - Symmetry in structure, i.e. change in SST on cooler side of asymmetrical filament shape is at least 30% of SST change for warmer side.\n",
    "    - **Fronts** - *A sharp, step-like change in SST*\n",
    "        - **If at least one of the filament defintions is not met, except for <font color = magenta> gradient threshold </font>, a filament is detected allowing for mutually exclusive recording of structures** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c292b9-355d-4537-ba1c-bc5d2dcc0f2c",
   "metadata": {},
   "source": [
    "2. **Data Ensemble** <br>\n",
    "    - Individual structures, fronts and filaments, are stored in respective dictionaries for either all cruises or a <font color = magenta> user specified date </font>\n",
    "    - Filaments\n",
    "        - Normalized origin for all structures at the local SST minima\n",
    "        - Limits of structure extend to bordering local maximas - hence parabolic shape\n",
    "    - Fronts \n",
    "        - Normalized origin at peak SST gradient\n",
    "        - Limits of fronts adjustable <font color = magenta> by length  </font> or default to neighboring minima and maxima.\n",
    "    **For ensembles of all data, users may <font color = magenta> normalize shape </font> by keeping 'cool' sides (side of lesser change) to left for fronts (asymmetrical filaments)** <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ac317-323d-4243-b34c-279c15aba551",
   "metadata": {},
   "source": [
    "3. **Saving Data - RECOMMENDED** <br>\n",
    "    - It is recommended that ensembles of fronts and filaments of all cruises are <font color = magenta> saved in .pkl files </font> - `front_ensemble` & `fil_ensemble`, respectively - for use in future scripts. **This is necessary for plotting probabilities of structures across bay.**\n",
    "    \n",
    "<font color = maroon> **Code is organized based on the three sections defined above, with <font color = magenta> parameter </font> definitions below** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b4d373-b1f5-4456-8faf-77fc90bbde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Edit Code --------- #\n",
    "\n",
    "# Detection Parameters\n",
    "window_size     = 25  # Multiply by 10 for physical distance (m) of smoothing relative to track\n",
    "gradient_thresh = 1.0 # in deg. C per KM\n",
    "extent          = .5 # Extent on either side a front's maximum gradient that is plotted. \n",
    "\n",
    "# Treating Data - true means removal (rmv)\n",
    "rmv_nan = False \n",
    "rmv_mdr = True\n",
    "\n",
    "# General Graphing Fontsizes\n",
    "fs_tick  = 35\n",
    "fs_label = 30 \n",
    "fs_title = 40\n",
    "\n",
    "# Individual Cruise or ALL Cruise Ensembles \n",
    "cruisedate = []   # Leave empty if no cruise \n",
    "\n",
    "# Normalize Cruise Data - set to false in code for indiviudal plots\n",
    "normalize_ensembles = False\n",
    "\n",
    "# Saving options\n",
    "saveplots      = False\n",
    "save_ensembles = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647db1d1-f44d-4a84-9b0a-40b51cd087c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ddff55-341e-4a82-aaf9-77020d80c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Import Libraries ----- #\n",
    "\n",
    "# Functions\n",
    "import numpy as np\n",
    "import functions as zf\n",
    "\n",
    "# Files\n",
    "import pickle\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors\n",
    "import matplotlib as mlb\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import Normalize, LogNorm, NoNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.axes as AX\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "#from matplotlib.axes import inset_axes\n",
    "\n",
    "# Mapping\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs #importing the cartopy coordinate reference system library\n",
    "import cartopy.feature as cfeature #importing the cartopy library of surface features\n",
    "import cartopy.io.shapereader as shpreader\n",
    "\n",
    "# Smoothing\n",
    "import scipy.io as sio\n",
    "import scipy.stats as ss\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import peak_prominences\n",
    "\n",
    "# ----- IMPORT Track dictionary as pkl ----- #\n",
    "# Read dictionary pkl file\n",
    "if len(cruisedate) != 0:\n",
    "    try:\n",
    "        with open(f'cruise_{cruisedate[0]}.pkl', 'rb') as ztd:\n",
    "            zodiac_track_data = pickle.load(ztd)\n",
    "    except:\n",
    "        with open('track_data.pkl', 'rb') as ztd:\n",
    "            zodiac_track_data = pickle.load(ztd)\n",
    "else:\n",
    "    with open('track_data.pkl', 'rb') as ztd:\n",
    "        zodiac_track_data = pickle.load(ztd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70464872-71fc-46a4-9606-0e62c12ddce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subset(arr1, arr2):\n",
    "\n",
    "    # Iterate over each element in the second array\n",
    "    for i in range(len(arr2)):\n",
    "        found = False\n",
    "\n",
    "        # Check if the element exists in the first array\n",
    "        for j in range(len(arr1)):\n",
    "            if arr2[i] == arr1[j]:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        # If any element is not found, return false\n",
    "        if not found:\n",
    "            return False\n",
    "\n",
    "    # If all elements are found, return true\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb043a-c247-4446-9b13-23f8abb1a068",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Automated Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a16ff08-3555-43c4-8596-271ae5c8889d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Filaments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886a6de-40b1-4958-9709-af953d905bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to fill #\n",
    "failed_dates   = [] # List of dates Zodiac did not leave\n",
    "zero_grad      = [] # indices of where a sst local max and min resides \n",
    "\n",
    "# Arrays for Data Analysis # \n",
    "filament_width = []\n",
    "fil_change     = []\n",
    "symmetry       = []\n",
    "\n",
    "# Ensemble of ALL filaments #\n",
    "filament_ensemble = {}\n",
    "\n",
    "# This master loop goes through each possible date the zodiac went out and grabs corresponding data \n",
    "num = 0 # For counting structures\n",
    "for index, date in enumerate(zodiac_track_data):\n",
    "        \n",
    "    # If we only want one cruise, we reset ensemble each iteration until proper date is found and loop is exited\n",
    "    # As we cycle through dates, we skip the rest of the loop until individual date is found\n",
    "    if len(cruisedate) != 0:\n",
    "        if cruisedate[0] == date:\n",
    "            filament_ensemble = {}\n",
    "            normalize_ensembles = False # Overwrites for individual plots \n",
    "        else:\n",
    "            continue \n",
    "\n",
    "    # Reset subset array to ensure there are no copies of the same structure\n",
    "    # NOTE: This means the same excat structure due to errors in surface sampler data, the same structure but at different\n",
    "    # positions may be marked multiple times - no other way to know...\n",
    "    subset_lat, subset_lon = [],[]\n",
    "\n",
    "    try:\n",
    "        lat, lon, SST, flu = zf.select_track(date, zodiac_track_data, excludenans=rmv_nan, excludemdr=rmv_mdr)\n",
    "        # Data Processing, Filtering, & Gradients for SST #\n",
    "        dist_processed, sst_processed = zf.data_processing(lat, lon, SST, 10)\n",
    "        grad_dist_sst, grad_sst, lat_sst, lon_sst, sst_filtered, dist_filtered = \\\n",
    "        zf.running_avg_filter(window_size, lat, lon, sst_processed, dist_processed)\n",
    "        # Data Processing, Filtering, & Gradients for Flu #\n",
    "        dist_processed, flu_processed = zf.data_processing(lat, lon, flu, 10)\n",
    "        grad_dist_flu, grad_flu, grad_lat_flu, grad_lon_flu, flu_filtered, dist_filtered = \\\n",
    "        zf.running_avg_filter(window_size, lat, lon, flu_processed, dist_processed)\n",
    "\n",
    "        # Get final details on cruise path - Bearing (Direction of boat)\n",
    "        bearing = np.around(zf.bearing(lat_sst, lon_sst), 2)\n",
    "        # split this into components (vector form)\n",
    "        lon_comp = 1*np.sin(np.around(bearing, 0)*(np.pi/180))\n",
    "        lat_comp = 1*np.cos(np.around(bearing, 0)*(np.pi/180))\n",
    "\n",
    "        # Find the local SST minimum and maximums #\n",
    "        sst_loc_max, _ = find_peaks(sst_filtered, height=0) # READ ABOUT FIND PEAKS ####\n",
    "        sst_loc_min, _ = find_peaks(-1*sst_filtered, height = -30)\n",
    "        zero_grad = np.concatenate((sst_loc_max, sst_loc_min))\n",
    "        # Brefily ensure they are ordered, as the minumums and maximum indices are appended out of order (not along track...)\n",
    "        for i in range(0, len(zero_grad)):\n",
    "            for j in range(i+1, len(zero_grad)):\n",
    "                if(zero_grad[i] > zero_grad[j]):\n",
    "                    temp = zero_grad[i];\n",
    "                    zero_grad[i] = zero_grad[j];\n",
    "                    zero_grad[j] = temp;\n",
    "\n",
    "        # With our organized array of local maximum and minimum indices, we begin selecting individual segments\n",
    "        start = 0 # Begin at 0th index\n",
    "        for i in range(len(zero_grad)-2):    \n",
    "\n",
    "            end = start+1                                     # Index to next one over \n",
    "            index1, index2 = zero_grad[start], zero_grad[end] # index 1 and 2 are now the indices that define 1/2 a segment \n",
    "            start = end                                       # Move start over 1 to grab next segment in loop\n",
    "\n",
    "            # Ensure that we start with a dip\n",
    "            if sst_filtered[index1] > sst_filtered[index2]:\n",
    "                # If true, we become concerned in other portion, hence index 3, which is the peak following our central minima\n",
    "                index3 = zero_grad[end+1]\n",
    "                # Make sure that somewhere in our filament there is a sufficiently large gradient \n",
    "                if (np.max(grad_sst[index1:index3]) >= gradient_thresh):\n",
    "\n",
    "                    # If true, check that we maintain a relatively straight bearing \n",
    "                    filament_xcomps, filament_ycomps = lon_comp[index1:index3], lat_comp[index1:index3]\n",
    "                    X, Y = lon_comp[index1], lat_comp[index1]\n",
    "                    angles = []\n",
    "                    for i in range(len(filament_xcomps)-1):\n",
    "                        try:\n",
    "                            xi, yi = filament_xcomps[i+1], filament_ycomps[i+1]\n",
    "                            angles = np.append(angles, (np.arccos(np.dot([X, Y], [xi, yi])/(np.sqrt(X**2 + Y**2)*np.sqrt(xi**2 + yi**2))))*(180/np.pi))\n",
    "                        except:\n",
    "                            angles = np.append(angles, np.mean(angles))\n",
    "                        continue\n",
    "                    # Ensuring that heading does not change more than 90 deg\n",
    "                    if np.max(angles) < 90:    \n",
    "                        # Save Filament Data # \n",
    "                        filament_distance = dist_filtered[index1:index3]\n",
    "                        filament_sst      = sst_filtered[index1:index3]\n",
    "                        filament_flu      = flu_filtered[index1:index3]\n",
    "                        filament_lat      = lat_sst[index1:index3]\n",
    "                        filament_lon      = lon_sst[index1:index3]\n",
    "\n",
    "                        # order from 'small' to 'large' change in SST \n",
    "                        if normalize_ensembles == True:\n",
    "                            if filament_sst[-1] < filament_sst[0]:\n",
    "                                filament_sst = filament_sst[::-1]\n",
    "                                filament_flu = filament_flu[::-1]\n",
    "                            # This impacts how we measure symmetry \n",
    "                            symm_test = (filament_sst[0]-np.min(filament_sst))/(filament_sst[-1]-np.min(filament_sst))\n",
    "                        else: \n",
    "                            # If we do not normalize, we still must ensure that symmetry test is done properly for \n",
    "                            # either case of asymmetry\n",
    "                            if filament_sst[-1] < filament_sst[0]:\n",
    "                                symm_test = (filament_sst[-1]-np.min(filament_sst))/(filament_sst[0]-np.min(filament_sst))\n",
    "                            else:\n",
    "                                symm_test = (filament_sst[0]-np.min(filament_sst))/(filament_sst[-1]-np.min(filament_sst))\n",
    "\n",
    "                        # FINAL CHECKS - SYMMETRY AND DISCONTINUITIES\n",
    "                        if (symm_test) >= .30:\n",
    "                            if len(np.diff(filament_distance)[np.diff(filament_distance) > 0.05]) == 0:\n",
    "\n",
    "                                # Normalize distances  \n",
    "                                index          = np.where(filament_sst == np.min(filament_sst))\n",
    "                                min_index      = index[0]\n",
    "                                equal_dist     = filament_distance - filament_distance[min_index] # Equidistant View of Front from minima\n",
    "\n",
    "                                # SST \n",
    "                                equal_sst = filament_sst - filament_sst[min_index]\n",
    "                                fil_symm  = (filament_sst[0]-np.min(filament_sst))/(filament_sst[-1]-np.min(filament_sst))\n",
    "\n",
    "                                # Positions of Filament (minima)\n",
    "                                min_lat = filament_lat[min_index]\n",
    "                                min_lon = filament_lon[min_index]\n",
    "                                # Orientation of Filament\n",
    "                                x_comp  = np.mean(filament_ycomps)\n",
    "                                y_comp  = np.mean(-1*filament_xcomps)\n",
    "\n",
    "                                # Ensure no repeat\n",
    "                                if not is_subset(subset_lat, np.round(min_lat,4)) and not is_subset(subset_lon, np.round(min_lon,4)):\n",
    "                                    # Set subset for this date to ensure same track is not checked twice\n",
    "                                    subset_lat = np.append(subset_lat, np.round(min_lat, 4))\n",
    "                                    subset_lon = np.append(subset_lon, np.round(min_lon,4))\n",
    "\n",
    "                                    # Counter\n",
    "                                    date_count = 1\n",
    "                                    fil_number = num+1 # adjusts for pythons zero-based indexing\n",
    "                                    num        = fil_number\n",
    "                                    print(f'Filament {fil_number} Detected on {date}', end = '\\r')\n",
    "                                    \n",
    "                                    # record stats\n",
    "                                    filament_width = np.append(filament_width, abs(equal_dist[0])+abs(equal_dist[-1])) # Single value for size of front\n",
    "                                    fil_change     = np.append(fil_change, np.abs(np.max(filament_sst)-np.min(filament_sst)))\n",
    "                                    symmetry       = np.append(symmetry, fil_symm)                                    \n",
    "\n",
    "                                    # Save details on filament in dictionary style\n",
    "                                    cruises = {'Date': (date), \\\n",
    "                                               # Filament Imaging\n",
    "                                               'Equi-Dist': (equal_dist), 'Equi-SST': (equal_sst), \\\n",
    "                                               # General Data\n",
    "                                               'Distance': (filament_distance), 'SST': (filament_sst), 'Flu': (filament_flu), \\\n",
    "                                               'Latitude': (filament_lat), 'Longitude': (filament_lon), \\\n",
    "                                               'Min-Lat': (min_lat), 'Min-Lon': (min_lon), \\\n",
    "                                               'x-comp': (x_comp), 'y-comp': (y_comp), \\\n",
    "                                               'Symmetry': (fil_symm)}\n",
    "\n",
    "                                    # Save to dictionary with corresponding number\n",
    "                                    filament_ensemble[fil_number] = cruises\n",
    "\n",
    "    except:\n",
    "            # Dates may fail based on above logicals of nans - cruises where TSG or fluorometer did not record\n",
    "            # and exclusion of MDR - cruises that did not leave marina\n",
    "            failed_dates = np.append(failed_dates, date)\n",
    "    continue \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d418b-186a-422e-8454-08fb2473e7e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2f689-0eae-4679-92ac-f57d0ca14bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to fill \n",
    "failed_dates = [] # List of dates Zodiac did not leave\n",
    "zero_grad    = [] # indices of where a sst local max and min resides \n",
    "\n",
    "# Arrays for Data Analysis \n",
    "front_width   = []\n",
    "front_change  = []\n",
    "\n",
    "# Ensemble of ALL Fronts\n",
    "front_ensemble = {}\n",
    "\n",
    "# This master loop is simply to go through each possible date the zodiac went out, and grab corresponding data \n",
    "num = 0 # For counting fronts in our ensemble\n",
    "for index, date in enumerate(zodiac_track_data):\n",
    "        \n",
    "    # If we only want one cruise, we reset ensemble each iteration until proper date is found and loop is exited\n",
    "    # As we cycle through dates, we skip the rest of the loop until individual date is found\n",
    "    if len(cruisedate) != 0:\n",
    "        if cruisedate[0] == date:\n",
    "            front_ensemble = {}\n",
    "            normalize_ensembles = False # Overwrites for individual plots \n",
    "        else:\n",
    "            continue \n",
    "            \n",
    "    # Reset subset array to ensure there are no copies of the same structure\n",
    "    # NOTE: This means the same excat structure due to errors in surface sampler data, the same structure but at different\n",
    "    # positions may be marked multiple times - no other way to know...\n",
    "    subset_lat, subset_lon = [],[]\n",
    "        \n",
    "    try: \n",
    "        lat, lon, SST, flu = zf.select_track(date, zodiac_track_data, excludenans=rmv_nan, excludemdr=rmv_mdr)\n",
    "\n",
    "        # Data Processing, Filtering, & Gradients for SST\n",
    "        dist_processed, sst_processed = zf.data_processing(lat, lon, SST, 10)\n",
    "        grad_dist_sst, grad_sst, lat_sst, lon_sst, sst_filtered, dist_filtered = \\\n",
    "        zf.running_avg_filter(window_size, lat, lon, sst_processed, dist_processed)\n",
    "        # Data Processing, Filtering, & Gradients for Flu\n",
    "        dist_processed, flu_processed = zf.data_processing(lat, lon, flu, 10)\n",
    "        grad_dist_flu, grad_flu, grad_lat_flu, grad_lon_flu, flu_filtered, dist_filtered = \\\n",
    "        zf.running_avg_filter(window_size, lat, lon, flu_processed, dist_processed)\n",
    "\n",
    "        # Find the local SST minimum and maximums\n",
    "        sst_loc_max, _ = find_peaks(sst_filtered, height=0)\n",
    "        sst_loc_min, _ = find_peaks(-1*sst_filtered, height = -30)\n",
    "        zero_grad = np.concatenate((sst_loc_max, sst_loc_min))\n",
    "        # Brefily ensure they are ordered, as the minumums and maximums are out of order (not along track...)\n",
    "        for i in range(0, len(zero_grad)):\n",
    "            for j in range(i+1, len(zero_grad)):\n",
    "                if(zero_grad[i] > zero_grad[j]):\n",
    "                    temp = zero_grad[i];\n",
    "                    zero_grad[i] = zero_grad[j];\n",
    "                    zero_grad[j] = temp;\n",
    "\n",
    "        # With our organized array of local maximum and minimums, we begin selecting individual segments\n",
    "        start = 0 # Begin at 0th index\n",
    "        for i in range(len(zero_grad)-1):\n",
    "            end = start+1 # Index to next one over \n",
    "            index1, index2 = zero_grad[start], zero_grad[end] # index 1 and 2 are now the indices that define one segment \n",
    "            start = end # Move start over 1 to grab next segment in loop\n",
    "\n",
    "            # With an individual segment selected, we grab its gradients and check whether it is a front\n",
    "            nonzero_gradients = grad_sst[index1:index2]\n",
    "            # since the front is of a large degree change, save its distance\n",
    "            if np.max(nonzero_gradients) >= gradient_thresh:\n",
    "\n",
    "                # Here, it has been proven that our segment exceeds a set threshold, and is indeed a front. Therefore grab other variables  \n",
    "                nonzero_gradient_distances = grad_dist_sst[index1:index2] \n",
    "                frontal_gradient = nonzero_gradients\n",
    "                frontal_distance = dist_filtered[index1:index2]           \n",
    "                frontal_sst      = sst_filtered[index1:index2]\n",
    "                frontal_flu      = flu_filtered[index1:index2]\n",
    "                # Record the position too, using boat positions \n",
    "                frontal_lat = lat_sst[index1:index2]\n",
    "                frontal_lon = lon_sst[index1:index2]\n",
    "\n",
    "                # Ensure that this front is not a part of a filament\n",
    "                filament = 0\n",
    "                for f in range(len(filament_ensemble)):\n",
    "                    if (filament_ensemble[f+1]['Date'] == date):\n",
    "                        fil_lat = filament_ensemble[f+1]['Latitude']\n",
    "                        fil_lon = filament_ensemble[f+1]['Longitude']\n",
    "                        if is_subset(fil_lat, frontal_lat) and is_subset(fil_lon, frontal_lon):\n",
    "                            #print(f'{dates[d]} number {(f)} is a filament')\n",
    "                            filament = 1\n",
    "                            break\n",
    "\n",
    "                if filament != 1:\n",
    "                    # We have a front and relevant information about that front. Before we proceed, lets make sure this front is 'legit'\n",
    "                    # in some cases, data outages may creates large gaps in data, placing two different water readings next to each other \n",
    "                    if len(np.diff(frontal_distance)[np.diff(frontal_distance) > 0.05]) == 0:\n",
    "                        # If there is not a large discontinuity across the bay, ensure that the removal of the marina has not created its own gap\n",
    "                        mdr_front_lat = frontal_lat[((frontal_lon > -118.481) & (frontal_lon < -118.418)) & ((frontal_lat < 33.984) & (frontal_lat > 33.936))]\n",
    "                        mdr_front_lon = frontal_lon[((frontal_lon > -118.481) & (frontal_lon < -118.418)) & ((frontal_lat < 33.984) & (frontal_lat > 33.936))]\n",
    "                        # if there is data right outside of marina we exclude these fronts from the data, such that the loop does not conitnue\n",
    "                        if (len(mdr_front_lat) == 0 ) and (len(mdr_front_lon) == 0):\n",
    "\n",
    "                            # Organize from cold to warm water, if not already, such that all fronts are interpreted along one direction\n",
    "                            if normalize_ensembles == True:\n",
    "                                if frontal_sst[-1] < frontal_sst[0]:\n",
    "                                    frontal_sst = frontal_sst[::-1]\n",
    "                                    frontal_flu = frontal_flu[::-1]\n",
    "                                    frontal_gradient = frontal_gradient[::-1]\n",
    "\n",
    "                            # Equidistant View of Front, for common origin in ensemble\n",
    "                            max_index  = np.where(frontal_gradient == np.max(frontal_gradient))[0]\n",
    "                            \n",
    "                            # Distances \n",
    "                            equal_dist = frontal_distance - frontal_distance[max_index-1]\n",
    "\n",
    "                            # SST \n",
    "                            equal_sst  = frontal_sst - frontal_sst[max_index-1]\n",
    "\n",
    "                            # Positions of front (max gradient)\n",
    "                            max_lat = frontal_lat[max_index]\n",
    "                            max_lon = frontal_lon[max_index]\n",
    "\n",
    "                            # Ensure no repeat\n",
    "                            if not is_subset(subset_lat, np.round(max_lat,5)) and not is_subset(subset_lon, np.round(max_lon,5)):\n",
    "                                # Set subset for this date to ensure same track is not checked twice\n",
    "                                subset_lat = np.append(subset_lat, np.round(max_lat, 5))\n",
    "                                subset_lon = np.append(subset_lon, np.round(max_lon, 5))\n",
    "\n",
    "                                # Counter\n",
    "                                front_number = num+1\n",
    "                                num = front_number\n",
    "                                print(f'Front {front_number} Detected on {date}', end = '\\r')\n",
    "                                \n",
    "                                # record stats \n",
    "                                front_width  = np.append(front_width, abs(equal_dist[0])+abs(equal_dist[-1])) # Single value for size of front\n",
    "                                front_change = np.append(front_change, np.abs(equal_sst[-1]-equal_sst[0]))\n",
    "\n",
    "                                # Save to Dictionary # \n",
    "                                          # Origin Based for Ensemble \n",
    "                                cruises = {'Date': (date), \\\n",
    "                                           # Frontal Imaging\n",
    "                                           'Equi-Dist': (equal_dist), 'Equi-SST': (equal_sst), \\\n",
    "                                           # General Data\n",
    "                                           'Distance': (frontal_distance), 'SST': (frontal_sst), 'Flu': (frontal_flu), \\\n",
    "                                           'Max-Lat': (max_lat), 'Max-Lon': (max_lon)}\n",
    "\n",
    "                                front_ensemble[front_number] = cruises\n",
    "        \n",
    "    except:\n",
    "        failed_dates = np.append(failed_dates, date)\n",
    "    continue "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c03542-e572-45c6-b5d2-3b93deea949e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Plots (Ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b03cb2-53e8-45d4-b4db-9f6f0e7d4d79",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Individual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345e811-39fe-40ef-93c8-89c0a29daf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(cruisedate) != 0:\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize = (20,10))\n",
    "    \n",
    "    plt.plot(dist_filtered, sst_filtered)\n",
    "    \n",
    "    bearing = np.around(zf.bearing(lat_sst, lon_sst), 2)\n",
    "    # split this into components (vector form)\n",
    "    lon_comp = 1*np.sin(np.around(bearing, 0)*(np.pi/180))\n",
    "    lat_comp = 1*np.cos(np.around(bearing, 0)*(np.pi/180))\n",
    "\n",
    "    x = dist_filtered\n",
    "    z = bearing \n",
    "    y = np.min(sst_filtered)*np.ones(len(dist_filtered)) - .01*np.min(sst_filtered)\n",
    "    \n",
    "    # Sort the x values and corresponding z values\n",
    "    sorted_indices = np.argsort(x)\n",
    "    x_sorted = x[sorted_indices]\n",
    "    z_sorted = z[sorted_indices]\n",
    "    \n",
    "    # Create segments for the line\n",
    "    points = np.array([x_sorted, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    \n",
    "    # Normalize colors for the colormap\n",
    "    norm = plt.Normalize(z_sorted.min(), z_sorted.max())\n",
    "    cmap = plt.cm.twilight_shifted # Choose a colormap\n",
    "    \n",
    "    # Create a LineCollection\n",
    "    line_collection = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "    line_collection.set_array(z_sorted[:-1])  # Set colors based on z values\n",
    "    line_collection.set_linewidth(30)  # Set thickness of the line\n",
    "\n",
    "    ax.add_collection(line_collection)\n",
    "    \n",
    "    if len(filament_ensemble) > 0:\n",
    "        for i in range(len(filament_ensemble)):\n",
    "            x=filament_ensemble[(i+1)]['Distance']\n",
    "            y=filament_ensemble[(i+1)]['SST']    \n",
    "            plt.plot(x, y, '-r')\n",
    "    if len(front_ensemble) > 0:\n",
    "        for i in range(len(front_ensemble)):\n",
    "            x=front_ensemble[(i+1)]['Distance']\n",
    "            y=front_ensemble[(i+1)]['SST']\n",
    "            plt.plot(x, y, '-g')\n",
    "    \n",
    "    # Add a colorbar\n",
    "    cbar = fig.colorbar(line_collection, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Boat Heading - North = 0/360$^{\\circ}$', fontsize = fs_tick)\n",
    "    cbar.set_ticks(np.arange(0,420,60))\n",
    "    cbar.ax.tick_params(labelsize=fs_tick-5)\n",
    "    \n",
    "    # Plot discontinuities \n",
    "    dist_track = []\n",
    "    if len(np.diff(dist_filtered)[np.diff(dist_filtered) > 0.05]) != 0:\n",
    "        breaks = np.where(np.diff(dist_filtered) > 0.05)[0]\n",
    "        start = 0\n",
    "        for b in range(len(breaks)):\n",
    "            dist_track.append(dist_filtered[start:breaks[b]+1])\n",
    "            start = breaks[b]+1\n",
    "            if (b+1) == len(breaks):\n",
    "                dist_track.append(dist_filtered[start::])\n",
    "    for n in range(len(dist_track)): \n",
    "        if (n > 0) and (n < len(dist_track)):\n",
    "            plt.axvspan(dist_track[n-1][-1], dist_track[n][0], color = 'gray', zorder = 0)\n",
    "\n",
    "    green_patch = mpatches.Patch(color='green', label='Front') \n",
    "    red_patch = mpatches.Patch(color='red', label='Filament')\n",
    "    gray_patch = mpatches.Patch(color='gray', label='Discontinuity')\n",
    "    plt.legend(handles=[green_patch, red_patch, gray_patch], loc='upper left', fontsize = fs_tick)\n",
    "    \n",
    "    plt.xticks(fontsize=fs_tick)\n",
    "    plt.yticks(fontsize=fs_tick)\n",
    "        \n",
    "    #plt.title(f'Automated Detection of SST Structures - {cruisedate[0]}', fontsize=fs_title)\n",
    "    plt.title(f'One Dimensional Track for {cruisedate[0]}', fontsize=fs_title)\n",
    "    plt.xlabel('Distance [km]', fontsize = fs_label)\n",
    "    plt.ylabel('SST [$^{\\circ}C$]', fontsize = fs_label)\n",
    "    plt.ylabel('Fluorescence [counts]', fontsize = fs_label)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "if len(cruisedate) != 0:\n",
    "    if saveplots == True:\n",
    "        filename = f'sst_track_{cruisedate[0]}.png'\n",
    "        plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7632c3bf-764a-4c94-9388-2722e687a76e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fluorescence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b309e122-8030-476c-9c0a-6f11ab9ac097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapped Individual Cruise #        \n",
    "if len(cruisedate) != 0 and rmv_nan:\n",
    "    \n",
    "    # scale plots \n",
    "    if max(lat_sst) > 33.9:\n",
    "        nrows = 2\n",
    "        ncols = 1\n",
    "        dims = (30,15)\n",
    "        cbar_scale = .8\n",
    "    if min(lat_sst) < 33.8:\n",
    "        nrows = 1\n",
    "        ncols = 2\n",
    "        dims = (20,15)\n",
    "        cbar_scale = .7\n",
    "    \n",
    "    track_fig, ax = plt.subplots(nrows,ncols,subplot_kw={'projection': ccrs.PlateCarree()}, figsize = dims)\n",
    "        \n",
    "    for plot in range(2):\n",
    "    \n",
    "        ax = plt.subplot(nrows, ncols, plot+1)\n",
    "\n",
    "        long_lat_coords = [-118.85, -118.25, 33.7, 34.05]\n",
    "        ax.set_extent(long_lat_coords)\n",
    "        ax.coastlines()\n",
    "        ax.add_feature(cfeature.OCEAN)\n",
    "        ax.add_feature(cfeature.LAND)\n",
    "        ax.add_feature(cfeature.COASTLINE)\n",
    "        \n",
    "        if rmv_mdr == True:\n",
    "            vertices = [-118.48, -118.417, 33.983902, 33.935]\n",
    "            x_origin, y_origin = vertices[0], vertices[2]\n",
    "            x_distance, y_distance = (vertices[1] - vertices[0]), (vertices[3] - vertices[2])\n",
    "            rectangle = mpatches.Rectangle((x_origin, y_origin), x_distance, y_distance, fc='grey',ec=\"red\")\n",
    "            plt.gca().add_patch(rectangle)\n",
    "            plt.axis('scaled')\n",
    "\n",
    "        if plot == 0:\n",
    "            plt.scatter(lon_sst, lat_sst, c = sst_filtered, cmap='jet')\n",
    "            plt.title('SST Track - $^{\\circ}$C', fontsize=fs_label)\n",
    "            cbar = plt.colorbar(shrink = cbar_scale)\n",
    "            cbar.ax.tick_params(labelsize=fs_tick-10)\n",
    "            for i in range(len(filament_ensemble)):\n",
    "                #plt.scatter(filament_ensemble[i+1]['Min-Lon'], filament_ensemble[i+1]['Min-Lat'], s = 100, color = 'red')\n",
    "                plt.text(filament_ensemble[i+1]['Min-Lon'], filament_ensemble[i+1]['Min-Lat'], f'{i+1}', \\\n",
    "                         fontsize = fs_label, color = 'magenta')\n",
    "            for i in range(len(front_ensemble)):\n",
    "                #plt.scatter(front_ensemble[i+1]['Max-Lon'], front_ensemble[i+1]['Max-Lat'], s = 100, color = 'magenta')\n",
    "                plt.text(front_ensemble[i+1]['Max-Lon'], front_ensemble[i+1]['Max-Lat'], f'{i+1}', \\\n",
    "                         fontsize = fs_label, color = 'black')\n",
    "                \n",
    "        else:\n",
    "            plt.scatter(lon_sst, lat_sst, c = flu_filtered, cmap = 'Greens')\n",
    "            plt.title('Flourescence Track - Raw Counts', fontsize=fs_label)\n",
    "            cbar = plt.colorbar(shrink = cbar_scale)\n",
    "            cbar.set_ticks(np.linspace(np.round(min(flu_filtered),0),np.round(max(flu_filtered),0),5))\n",
    "            cbar.ax.tick_params(labelsize=fs_tick-10)\n",
    "\n",
    "        plt.xlim(min(lon_sst)-.01, max(lon_sst)+.01)\n",
    "        plt.ylim(min(lat_sst)-.01, max(lat_sst)+.01)\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    \n",
    "if len(cruisedate) != 0:\n",
    "    if saveplots == True:\n",
    "        filename = f'mapped_cruise_{cruisedate[0]}.png'\n",
    "        plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361878e-b4b7-4fe2-94b5-083fc0c285af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Structure Plots - OPTIONAL \n",
    "if len(cruisedate) != 0 and rmv_nan:\n",
    "    \n",
    "    from scipy.signal import find_peaks, peak_prominences\n",
    "\n",
    "    # from above mapped track, select between front or filament and map said specific feature by number \n",
    "    front  = True \n",
    "    number = 6\n",
    "        \n",
    "    fig, ax1 = plt.subplots(1, figsize = (30,13))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    if front:\n",
    "        dis = front_ensemble[number]['Equi-Dist']\n",
    "        sst = front_ensemble[number]['SST']\n",
    "        flu = front_ensemble[number]['Flu']\n",
    "    else:\n",
    "        dis = filament_ensemble[number]['Equi-Dist']\n",
    "        sst = filament_ensemble[number]['SST']\n",
    "        flu = filament_ensemble[number]['Flu']\n",
    "        \n",
    "    # norm flu\n",
    "    flu = (flu - min(flu)) / (max(flu) -min(flu))\n",
    "    \n",
    "    # Plotting\n",
    "    ax1.plot(dis, sst, color = 'lightcoral')\n",
    "    ax2.plot(dis, flu, color = 'seagreen')\n",
    "    max_flu_index = np.where(flu == np.max(flu))[0]\n",
    "    ax1.axvline(dis[max_flu_index], color = 'gray')\n",
    "    \n",
    "    # Plot peaks\n",
    "    peaks, _ = find_peaks(flu)\n",
    "    prominences = peak_prominences(flu, peaks)[0]\n",
    "    max_prom = peaks[np.where(prominences == np.max(prominences))[0]]\n",
    "    ax1.axvline(dis[max_prom], color = 'gray')\n",
    "\n",
    "    # Edit plot\n",
    "    ax1.set_xlabel('Distance from Center', fontsize = fs_label)\n",
    "    ax1.set_ylabel('SST', fontsize = fs_label)\n",
    "    ax2.set_ylabel('Fluorescence [Normalized]', fontsize = fs_label)\n",
    "    ax1.yaxis.label.set_color('lightcoral')\n",
    "    ax2.yaxis.label.set_color('seagreen')\n",
    "    ax1.tick_params(axis='both', labelsize=fs_tick)\n",
    "    ax2.tick_params(axis='both', labelsize=fs_tick)\n",
    "    \n",
    "    # Label peak prominences if any\n",
    "    for i in range(len(peaks)):\n",
    "        ax2.plot(dis[peaks[i]], flu[peaks[i]], 'g*')\n",
    "        ax2.text(dis[peaks[i]], flu[peaks[i]], f'{prominences[i]: .2f}', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed6fee-fe5e-4cd9-8169-108ac8be90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rmv_nan and len(cruisedate) != 0:\n",
    "    \n",
    "    dis_prom_front, val_prom_front = [], []\n",
    "    dis_prom_fil, val_prom_fil = [], []\n",
    "        \n",
    "    # Go through all filaments and fronts and calculate peak prominence position and its respective value\n",
    "\n",
    "    # 1 - Select between fronts (0) and filaments (1)\n",
    "    for structure in range(2):\n",
    "        \n",
    "        if structure == 0:\n",
    "            for number in range(len(front_ensemble)):\n",
    "                dis = front_ensemble[number+1]['Equi-Dist']\n",
    "                sst = front_ensemble[number+1]['SST']\n",
    "                flu = front_ensemble[number+1]['Flu']\n",
    "                \n",
    "                # 2 - Normalize fluorescence and distance \n",
    "                # 2.1: Flu\n",
    "                flu = (flu - min(flu)) / (max(flu) -min(flu))\n",
    "                # 2.2: dis\n",
    "                #dis[dis < 0] = -1* ((dis[dis < 0]) / (min(dis[dis < 0])))\n",
    "                #dis[dis > 0] = ((dis[dis > 0]) / (max(dis[dis > 0])))\n",
    "\n",
    "                # 3 - Calc promincences and find highes ones distance from structure\n",
    "                try:\n",
    "                    peaks, _ = find_peaks(flu)\n",
    "                    prominences = peak_prominences(flu, peaks)[0]\n",
    "                    max_prom = peaks[np.where(prominences == np.max(prominences))[0]]\n",
    "                    # record values \n",
    "                    #dis_prom = np.append(dis_prom, dis[max_prom])\n",
    "                    #val_prom = np.append(val_prom, np.max(prominences))\n",
    "                    if len(max_prom) != 2:\n",
    "                        # record values \n",
    "                        dis_prom_front = np.append(dis_prom_front, dis[max_prom])\n",
    "                        val_prom_front = np.append(val_prom_front, np.max(prominences))\n",
    "                except:\n",
    "                    #print(f'No peak for front {number+1}')\n",
    "                    pass\n",
    "        else:\n",
    "            for number in range(len(filament_ensemble)):\n",
    "                dis = filament_ensemble[number+1]['Equi-Dist']\n",
    "                sst = filament_ensemble[number+1]['SST']\n",
    "                flu = filament_ensemble[number+1]['Flu']\n",
    "        \n",
    "                # 2 - Normalize fluorescence and distance \n",
    "                # 2.1: Flu\n",
    "                flu = (flu - min(flu)) / (max(flu) -min(flu))\n",
    "                # 2.2: dis\n",
    "                #dis[dis < 0] = -1* ((dis[dis < 0]) / (min(dis[dis < 0])))\n",
    "                #dis[dis > 0] = ((dis[dis > 0]) / (max(dis[dis > 0])))\n",
    "\n",
    "                # 3 - Calc promincences and find highes ones distance from structure\n",
    "                try:\n",
    "                    peaks, _ = find_peaks(flu)\n",
    "                    prominences = peak_prominences(flu, peaks)[0]\n",
    "                    max_prom = peaks[np.where(prominences == np.max(prominences))[0]]\n",
    "                    # record values \n",
    "                    dis_prom_fil = np.append(dis_prom_fil, dis[max_prom])\n",
    "                    val_prom_fil = np.append(val_prom_fil, np.max(prominences))\n",
    "                    if len(dis_prom) != len(val_prom):\n",
    "                        print(structure, number)\n",
    "                        break\n",
    "                except:\n",
    "                    #print(f'No peak for front {number+1}')\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ce0c7-54dc-4890-afee-54ab006f1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rmv_nan and len(cruisedate) != 0:\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize = (25,13))\n",
    "\n",
    "    # Plot data \n",
    "    plt.scatter(np.abs(dis_prom_front), val_prom_front, s = 100, color = 'k', label = 'Front')\n",
    "    plt.scatter(np.abs(dis_prom_fil), val_prom_fil, s = 100, color = 'magenta', label = 'Filament')\n",
    "    \n",
    "    # Add bounds\n",
    "    ax.axvline(0, color = 'gray', linestyle = '--')\n",
    "    ax.axhline(0, color = 'gray', linestyle = '--')\n",
    "    \n",
    "    plt.legend(fontsize = fs_tick)\n",
    "    \n",
    "#     ax.axvline(-1, color = 'blue', linestyle = '--')\n",
    "#     ax.text(-1, .8, 'Side of filament of < $\\Delta_{SST}$', \\\n",
    "#              color = 'blue', rotation = 270, verticalalignment='top', horizontalalignment='left', fontsize = fs_tick)\n",
    "#     ax.axvline(1, color = 'red', linestyle = '--')\n",
    "#     ax.text(1, .8, 'Side of filament of > $\\Delta_{SST}$', \\\n",
    "#              color = 'red', rotation = 270, verticalalignment='top', horizontalalignment='right', fontsize = fs_tick)\n",
    " \n",
    "    # edit graph\n",
    "    plt.xlim(-.01, 1.01)\n",
    "    plt.ylim(-.05, 1.01)\n",
    "    ax.tick_params(axis='both', labelsize=fs_tick)\n",
    "    ax.set_xlabel('Distance from Center [kilometers]', fontsize = fs_label)\n",
    "    ax.set_ylabel('Peak Prominence', fontsize = fs_label)\n",
    "    plt.title(f'Peak Prominence versus Distance from Center', fontsize = fs_title)\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa7ff91-2e34-4282-b25e-2bb80563305c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c06db-6ed3-4dca-8be2-219b17f62f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_ens_fig = plt.figure(1, (20, 10)) \n",
    "\n",
    "# extent of ensemble in km from max gradient\n",
    "extent = .5\n",
    "\n",
    "plt.axhline(y=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "plt.axvline(x=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "\n",
    "for i in range(len(filament_ensemble)):\n",
    "    x = filament_ensemble[i+1]['Equi-Dist']\n",
    "    y = filament_ensemble[i+1]['Equi-SST']\n",
    "\n",
    "    if max(y) <= .5:\n",
    "        plt.plot(x, y, color = 'green', zorder=4)\n",
    "    elif max(y) <= 1.0:\n",
    "        plt.plot(x, y, color = 'blue', zorder=3)\n",
    "    elif max(y) <= 1.5:\n",
    "        plt.plot(x, y, color = 'orange', zorder=2)\n",
    "    else:\n",
    "        plt.plot(x, y, color = 'red', zorder=1)\n",
    "        \n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-.1, 1.7)\n",
    "\n",
    "plt.xlabel('Distance from Minimum SST [km]', fontsize=fs_label)\n",
    "plt.ylabel('$\\Delta$SST from Minimum [$^{\\circ}C$]', fontsize=fs_label)\n",
    "\n",
    "if len(cruisedate) != 0:\n",
    "    plt.title(f'{cruisedate[0]} Ensemble of Filaments - {len(filament_ensemble)} Total', fontsize=fs_title)\n",
    "else:\n",
    "    plt.title(f'Ensemble of Filaments - {len(filament_ensemble)} Total', fontsize=fs_title)\n",
    "\n",
    "green_patch = mpatches.Patch(color='green', label='$\\Delta_{max}$ $\\leq$ .5') \n",
    "blue_patch = mpatches.Patch(color='blue', label='.5 < $\\Delta_{max}$ $\\leq$ 1.0')\n",
    "orange_patch = mpatches.Patch(color='orange', label='1.0 < $\\Delta_{max}$ $\\leq$ 1.5')\n",
    "red_patch = mpatches.Patch(color='red', label='$\\Delta_{max}$ > 1.5')\n",
    "plt.legend(handles=[green_patch, blue_patch, orange_patch, red_patch], fontsize = fs_tick-10, loc = 'upper left')\n",
    "\n",
    "plt.xticks(fontsize=fs_tick), plt.yticks(fontsize=fs_tick)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#print(f'Cruise Dates: \\n {dates}')\n",
    "\n",
    "if saveplots == True:\n",
    "    plt.savefig('all_filament_ensemble.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f82d2-8930-4fed-8664-18e790897472",
   "metadata": {},
   "outputs": [],
   "source": [
    "front_ens_subplots, ax = plt.subplots(2, 2, figsize=(18, 12))  # 3 rows, 1 colum\n",
    "\n",
    "dates = []\n",
    "uhlf_km, ohlf_km, over_km, ovr_hkm = 0,0,0,0\n",
    "\n",
    "sum = 0\n",
    "for i in range(len(front_ensemble)):\n",
    "    x = front_ensemble[i+1]['Equi-Dist']\n",
    "    y = front_ensemble[i+1]['Equi-SST']\n",
    "    # Focus on certain part of front\n",
    "    y = y[(x >= -1*extent) & (x <= extent)]\n",
    "    x = x[(x >= -1*extent) & (x <= extent)]\n",
    "    if front_width[i] > 5:\n",
    "        continue\n",
    "    sum = i + 1\n",
    "    if front_change[i] <= .5:\n",
    "        ax[0,0].plot(x, y, color = 'green', zorder=4, alpha = .7)\n",
    "        uhlf_km = uhlf_km+1\n",
    "    elif front_change[i] <= 1:\n",
    "        ax[0,1].plot(x, y, color = 'blue', zorder=3, alpha = .7)\n",
    "        ohlf_km = ohlf_km+1\n",
    "    elif front_change[i] <= 1.5:\n",
    "        ax[1,0].plot(x, y, color = 'orange', zorder=2)\n",
    "        over_km = over_km+1\n",
    "    else:\n",
    "        ax[1,1].plot(x, y, color = 'red', zorder=1)\n",
    "        ovr_hkm = ovr_hkm+1\n",
    "        \n",
    "dates = np.unique(date)\n",
    "\n",
    "title_strings = ['$\\Delta_{sst} \\leq .5^{\\circ}C$', '$.5^{\\circ}C$ < $\\Delta_{sst}$ $\\leq$ 1.0$^{\\circ}C$', \\\n",
    "                 '$1.0^{\\circ}C$ < $\\Delta_{sst}$ $\\leq$ $1.5^{\\circ}C$', '$\\Delta_{sst}$ > $1.5^{\\circ}C$']\n",
    "number_front_perplot = [uhlf_km, ohlf_km, over_km, ovr_hkm]\n",
    "\n",
    "k = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i,j].axhline(0, linestyle = '--', color = 'k', alpha = .5)\n",
    "        ax[i,j].axvline(0, linestyle = '--', color = 'k', alpha = .5)\n",
    "        ax[i,j].set_xlim(-1*extent,extent)\n",
    "        ax[i,j].tick_params(axis='both', labelsize=15)\n",
    "        ax[i,j].set_title(title_strings[k], fontsize = 20)\n",
    "        ax[i,j].text(-.48, 0, f'{number_front_perplot[k]}', fontsize=fs_label, va = 'bottom')\n",
    "        k = k + 1\n",
    "        \n",
    "front_ens_subplots.suptitle('Front Ensemble by Total Change in SST ($\\Delta_{sst}$)' f' - {np.sum(number_front_perplot)} Total', fontsize = fs_label)\n",
    "front_ens_subplots.supxlabel('Distance from Maximum SST Gradient [km]', fontsize = fs_label)   \n",
    "front_ens_subplots.supylabel('$\\Delta$SST from Max Gradient [$^{\\circ}C$]', fontsize = fs_label)\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "if saveplots == True:\n",
    "    plt.savefig('front_ens_subplots.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9446883-f490-4ab5-8a9e-32144f8aceeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Saving Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f3ef4-d5a8-4a2a-be09-7cbb0a4cdc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_ensembles:    \n",
    "    import pickle\n",
    "    with open('filament_ensemble.pkl', 'wb') as ztd:\n",
    "        pickle.dump(filament_ensemble, ztd)\n",
    "        print('filament ensemble saved successfully to file')\n",
    "    with open('front_ensemble.pkl', 'wb') as ztd:\n",
    "        pickle.dump(front_ensemble, ztd)\n",
    "        print('front ensemble saved successfully to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c18b80a-1151-450f-9ecd-c3a7d2ccd390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
