{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5294b8d2-92d4-4656-bd13-d8ffd45f378f",
   "metadata": {},
   "source": [
    "## Methods for Detecting SST Structures: Fronts and Filaments\n",
    "### *Using 1D Cruise tracks*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c86b8-708e-4d8e-b5e5-1a7523c18bfe",
   "metadata": {},
   "source": [
    "This script will walk through the methodolgies described for the detection of fronts and filaments using 1D tracks of SST. The script is broken into two parts, the first being filaments and the second front methods. At the end, additional plots are generated for the ensembles of each respective set as well as investigation into fluorometry data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b4d373-b1f5-4456-8faf-77fc90bbde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Edit Code --------- #\n",
    "\n",
    "# Detection Parameters #\n",
    "window_size = 25 # Multiply by 10 for physical distance of smoothing relative to track\n",
    "gradient_thresh = 1.0 # in deg. C per KM\n",
    "\n",
    "# General Graphing Params #\n",
    "fs_tick = 25\n",
    "fs_label = 30\n",
    "fs_title = 40\n",
    "\n",
    "# Other #\n",
    "individual_cruise_ensemble = False\n",
    "dates = ['280415']\n",
    "#dates = ['20180305']\n",
    "saveplots = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647db1d1-f44d-4a84-9b0a-40b51cd087c7",
   "metadata": {},
   "source": [
    "#### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ddff55-341e-4a82-aaf9-77020d80c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Import Libraries ----- #\n",
    "\n",
    "# Functions\n",
    "import numpy as np\n",
    "import revisedZodiacFunctions as zf\n",
    "\n",
    "# Files\n",
    "import pickle\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors\n",
    "import matplotlib as mlb\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import Normalize, LogNorm, NoNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.axes as AX\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "#from matplotlib.axes import inset_axes\n",
    "\n",
    "# Mapping\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs #importing the cartopy coordinate reference system library\n",
    "import cartopy.feature as cfeature #importing the cartopy library of surface features\n",
    "import cartopy.io.shapereader as shpreader\n",
    "\n",
    "# Smoothing\n",
    "import scipy.io as sio\n",
    "import scipy.stats as ss\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import peak_prominences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0a2165-f61c-4ccc-a4b1-ffb6f67fc451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- DONT EDIT Code --------- #\n",
    "if individual_cruise_ensemble == True:\n",
    "    normalize_ensembles = False\n",
    "else:\n",
    "    normalize_ensembles = True\n",
    "    dates = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb043a-c247-4446-9b13-23f8abb1a068",
   "metadata": {},
   "source": [
    "### Generating Ensembles \n",
    "Before ensembles are made, the necessary pickle files that contain all relevant data from the Zodiac must be imported. Additionally, to sort through the data, organized by date, an array of all possible dates from the 2015-2023 span is made for automated indexing of cruise tracks. The decision for doing ensembles for individual cruises is ALSO possible! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce496b2-b145-4b0e-aa17-a704f287e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- IMPORT Track dictionary as pkl ----- #\n",
    "# Read dictionary pkl file\n",
    "with open('track_data.pkl', 'rb') as ztd:\n",
    "    zodiac_track_data = pickle.load(ztd)\n",
    "    \n",
    "# CHECK - uncomment to view all cruises #\n",
    "#zodiac_track_data\n",
    "\n",
    "# ----- Create array of dates ----- #\n",
    "# These strings will be used to generate the subsequent array which holds all of our dates to run through when collating \n",
    "# ALL of the Zodiac data \n",
    "# year_strings = ['15', '16', '17', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "# month_strings = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12'] \n",
    "# day_strings = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10',\n",
    "#                  '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', \n",
    "#                  '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "\n",
    "# # Compile all possible dates #\n",
    "# if individual_cruise_ensemble == False:\n",
    "#     for y in range(len(year_strings)):\n",
    "#         year = year_strings[y]\n",
    "#         for m in range(len(month_strings)):\n",
    "#             month = month_strings[m]\n",
    "#             for d in range(len(day_strings)):\n",
    "#                 day = day_strings[d]\n",
    "#                 # Before we are done with 2017 - year[3] - we must swicth the way in which we label the date as this when \n",
    "#                 # the means of recording cruise date switched from the two forms seen below \n",
    "#                 if y < 3:\n",
    "#                     date = day+month+year\n",
    "#                 else:\n",
    "#                     date = year+month+day\n",
    "#                 dates = np.append(dates, date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a16ff08-3555-43c4-8596-271ae5c8889d",
   "metadata": {},
   "source": [
    "#### Filaments \n",
    "We first generate the ensemble of detected filaments as these are structures with gradients on both sides of a clear local SST minima. Therefore it can be said that there are fronts within filaments. So filaments are found first with their GPS positions to compare to the positions of fronts in the next ensemble, removing any matching structures! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5886a6de-40b1-4958-9709-af953d905bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1574134/743256825.py:77: RuntimeWarning: invalid value encountered in arccos\n",
      "  angles = np.append(angles, (np.arccos(np.dot([X, Y], [xi, yi])/(np.sqrt(X**2 + Y**2)*np.sqrt(xi**2 + yi**2))))*(180/np.pi))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filament 198 Detected on 20231001\r"
     ]
    }
   ],
   "source": [
    "# Arrays to fill #\n",
    "failed_dates   = [] # List of dates Zodiac did not leave\n",
    "zero_grad      = [] # indices of where a sst local max and min resides \n",
    "\n",
    "# Arrays for Data Analysis # \n",
    "filament_width = []\n",
    "symmetry       = []\n",
    "\n",
    "# Ensemble of ALL filaments #\n",
    "filament_ensemble = {}\n",
    "\n",
    "# Needed values #\n",
    "compass_range=np.arange(180, 361, 1)\n",
    "compass_range = np.append(compass_range, compass_range[::-1])\n",
    "\n",
    "# This master loop is simply to go through each possible date the zodiac went out, and grab corresponding data \n",
    "num = 0 # For counting fronts for our ensemble\n",
    "for index, date in enumerate(zodiac_track_data):\n",
    "    try:\n",
    "        # FUNCTION WILL GRAB DICTIONARY WITH CORREPSONDING DATE AND REMOVE NANS AS WELL AS ENSURE DATA IS IN DEFINED BOUNDS OF SMB - EXCLUDING MARINA\n",
    "        specific_track, lat, lon, SST, flu = zf.track_selector(date, zodiac_track_data, excludenans=True, excludemdr=True)\n",
    "        # Data Processing, Filtering, & Gradients for SST #\n",
    "        dist_processed, sst_processed = zf.data_processing(lat, lon, SST, 10)\n",
    "        grad_dist_sst, grad_sst, lat_sst, lon_sst, sst_filtered, dist_filtered = \\\n",
    "        zf.running_avg_filter(window_size, lat, lon, sst_processed, dist_processed)\n",
    "        # Data Processing, Filtering, & Gradients for Flu #\n",
    "        dist_processed, flu_processed = zf.data_processing(lat, lon, flu, 10)\n",
    "        grad_dist_flu, grad_flu, grad_lat_flu, grad_lon_flu, flu_filtered, dist_filtered = \\\n",
    "        zf.running_avg_filter(window_size, lat, lon, flu_processed, dist_processed)\n",
    "    except:\n",
    "        failed_dates = np.append(failed_dates, date)\n",
    "        pass\n",
    "    # Get final details on cruise path - Bearing (Direction of boat)\n",
    "    bearing = np.around(zf.bearing(lat_sst, lon_sst), 2)\n",
    "    # split this into components (vector form)\n",
    "    lon_comp = 1*np.sin(np.around(bearing, 0)*(np.pi/180))\n",
    "    lat_comp = 1*np.cos(np.around(bearing, 0)*(np.pi/180))\n",
    "                    \n",
    "    # Find the local SST minimum and maximums #\n",
    "    sst_loc_max, _ = find_peaks(sst_filtered, height=0) # READ ABOUT FIND PEAKS ####\n",
    "    sst_loc_min, _ = find_peaks(-1*sst_filtered, height = -30)\n",
    "    zero_grad = np.concatenate((sst_loc_max, sst_loc_min))\n",
    "    # Brefily ensure they are ordered, as the minumums and maximum indices are appended out of order (not along track...)\n",
    "    for i in range(0, len(zero_grad)):\n",
    "        for j in range(i+1, len(zero_grad)):\n",
    "            if(zero_grad[i] > zero_grad[j]):\n",
    "                temp = zero_grad[i];\n",
    "                zero_grad[i] = zero_grad[j];\n",
    "                zero_grad[j] = temp;\n",
    "                \n",
    "    # With our organized array of local maximum and minimum indices, we begin selecting individual segments\n",
    "    start = 0 # Begin at 0th index\n",
    "    for i in range(len(zero_grad)-2):    \n",
    "        # Filament #\n",
    "        end = start+1 # Index to next one over \n",
    "        index1, index2 = zero_grad[start], zero_grad[end] # index 1 and 2 are now the indices that define 1/2 a segment \n",
    "        start = end # Move start over 1 to grab next segment in loop\n",
    "\n",
    "        #print(f'Checking for Filament')\n",
    "        \n",
    "        # Check for Filament #\n",
    "        # Ensure that we start with a dip\n",
    "        if sst_filtered[index1] > sst_filtered[index2]:\n",
    "            # If true we become concerned in other portion, hence index 3, which is the peak following our central minima\n",
    "            index3 = zero_grad[end+1]\n",
    "            # Make sure that somewhere in our filament there is a sufficiently large gradient \n",
    "            #if np.max(grad_sst[index1:index2]) >= gradient_thresh and np.max(grad_sst[index2:index3]) >= gradient_thresh:\n",
    "            if (np.max(grad_sst[index1:index3]) >= gradient_thresh):\n",
    "                \n",
    "                # Check that we maintain a relatively straight bearing \n",
    "                filament_xcomps, filament_ycomps = lon_comp[index1:index3], lat_comp[index1:index3]\n",
    "                X, Y = lon_comp[index1], lat_comp[index1]\n",
    "                angles = []\n",
    "                for i in range(len(filament_xcomps)-1):\n",
    "                    try:\n",
    "                        xi, yi = filament_xcomps[i+1], filament_ycomps[i+1]\n",
    "                        angles = np.append(angles, (np.arccos(np.dot([X, Y], [xi, yi])/(np.sqrt(X**2 + Y**2)*np.sqrt(xi**2 + yi**2))))*(180/np.pi))\n",
    "                    except:\n",
    "                        angles = np.append(angles, np.mean(angles))\n",
    "                    continue\n",
    "                # Ensure that heading does not change more than 90 deg\n",
    "                if np.max(angles) < 90:    \n",
    "                    # Save Filament Data # \n",
    "                    filament_distance = dist_filtered[index1:index3]\n",
    "                    filament_sst      = sst_filtered[index1:index3]\n",
    "                    filament_flu      = flu_filtered[index1:index3]\n",
    "                    filament_lat      = lat_sst[index1:index3]\n",
    "                    filament_lon      = lon_sst[index1:index3]\n",
    "\n",
    "                    if normalize_ensembles == True:\n",
    "                    # ORGANIZE DATA #\n",
    "                    # order from 'small' to 'large' sides \n",
    "                        if filament_sst[-1] < filament_sst[0]:\n",
    "                            filament_sst = filament_sst[::-1]\n",
    "                            filament_flu = filament_flu[::-1]\n",
    "                        symm_test = (filament_sst[0]-np.min(filament_sst))/(filament_sst[-1]-np.min(filament_sst))\n",
    "                    else: \n",
    "                        if filament_sst[-1] < filament_sst[0]:\n",
    "                            symm_test = (filament_sst[-1]-np.min(filament_sst))/(filament_sst[0]-np.min(filament_sst))\n",
    "                        else:\n",
    "                            symm_test = (filament_sst[0]-np.min(filament_sst))/(filament_sst[-1]-np.min(filament_sst))\n",
    "                            \n",
    "                    # FINAL CHECKS - SYMMETRY AND DISCONTINUITIES #\n",
    "                    if (symm_test) >= .30:\n",
    "                        if len(np.diff(filament_distance)[np.diff(filament_distance) > 0.05]) == 0:\n",
    "\n",
    "                            # Normalize distances  \n",
    "                            index = np.where(filament_sst == np.min(filament_sst))\n",
    "                            min_index = index[0]\n",
    "                            equal_dist = filament_distance - filament_distance[min_index-1] # Equidistant View of Front from minima\n",
    "                            filament_width = np.append(filament_width, abs(equal_dist[0])+abs(equal_dist[-1])) # Single value for size of front\n",
    "    \n",
    "                            # SST # \n",
    "                            equal_sst = filament_sst - filament_sst[min_index]\n",
    "                            #prcnt_sst = ((filament_sst - filament_sst[0])/(filament_sst[-1] - filament_sst[0]))*100\n",
    "                            fil_symm = (filament_sst[0]-np.min(filament_sst))/(filament_sst[-1]-np.min(filament_sst))\n",
    "                            symmetry = np.append(symmetry, fil_symm)\n",
    "\n",
    "                            # Positions of Filament (minima) #\n",
    "                            min_lat = filament_lat[min_index]\n",
    "                            min_lon = filament_lon[min_index]\n",
    "                            # Orientation of Filament #\n",
    "                            # x_comp  = filament_ycomps[min_index]\n",
    "                            # y_comp  = -1*filament_xcomps[min_index]\n",
    "                            x_comp  = np.mean(filament_ycomps)\n",
    "                            y_comp  = np.mean(-1*filament_xcomps)\n",
    "                            \n",
    "                            # Counter #\n",
    "                            fil_number = num+1\n",
    "                            num = fil_number\n",
    "                            print(f'Filament {fil_number} Detected on {date}', end = '\\r')\n",
    "    \n",
    "                            # Save to Dictionary # \n",
    "                            # Origin Based for Ensemble \n",
    "                            cruises = {'Date': (date), \\\n",
    "                                       # Filament Imaging\n",
    "                                       'Equi-Dist': (equal_dist), 'Equi-SST': (equal_sst), \\\n",
    "                                       # General Data\n",
    "                                       'Distance': (filament_distance), 'SST': (filament_sst), 'Flu': (filament_flu), \\\n",
    "                                       'Latitude': (filament_lat), 'Longitude': (filament_lon), \\\n",
    "                                       'Min-Lat': (min_lat), 'Min-Lon': (min_lon), \\\n",
    "                                       'x-comp': (x_comp), 'y-comp': (y_comp), \\\n",
    "                                       'Symmetry': (fil_symm)}\n",
    "                            filament_ensemble[str(fil_number)] = cruises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccb4de02-e4a2-4743-9c46-82b8153b8bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['010515', '071115', '141115', '040316', '150317', '20170718',\n",
       "       '20171110', '20180405', '20180502', '20180515', '20181015',\n",
       "       '20181110', '20181117', '20181130', '20190608', '20190731',\n",
       "       '20190925', '20191027', '20200208', '20200213', '20200416',\n",
       "       '20200428', '20200522', '20200914', '20210713', '20210715',\n",
       "       '20210720', '20210816', '20211112', '20211113', '20211114',\n",
       "       '20211115', '20211130', '20211201', '20211203', '20211210',\n",
       "       '20220126', '20220203', '20220211', '20220214', '20220216',\n",
       "       '20220224', '20220228', '20220302', '20220428', '20220601',\n",
       "       '20220630', '20220727', '20220930', '20221101', '20221104',\n",
       "       '20221110', '20221111', '20221114', '20221115', '20221118',\n",
       "       '20221121', '20221122', '20221123', '20221202', '20221206',\n",
       "       '20221209', '20230124', '20230302', '20230609', '20230830',\n",
       "       '20230831', '20231212', '20231213'], dtype='<U32')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca17b041-6f2c-49d8-9827-17f5e7181bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170718\n",
      "20211113\n",
      "20211115\n",
      "20220203\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(failed_dates)):\n",
    "    date = failed_dates[i]\n",
    "    specific_track, lat, lon, SST, flu = zf.track_selector(date, zodiac_track_data, excludenans=True, excludemdr=True)\n",
    "    if len(lat) != 0:\n",
    "        print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "994626c1-f886-4952-bac8-ec65065e5c22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m specific_track, lat, lon, SST, flu \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mtrack_selector(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20220203\u001b[39m\u001b[38;5;124m'\u001b[39m, zodiac_track_data, excludenans\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, excludemdr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(lon, lat, SST)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/pyplot.py:3687\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   3668\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[1;32m   3669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[1;32m   3670\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3685\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3686\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PathCollection:\n\u001b[0;32m-> 3687\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mscatter(\n\u001b[1;32m   3688\u001b[0m         x,\n\u001b[1;32m   3689\u001b[0m         y,\n\u001b[1;32m   3690\u001b[0m         s\u001b[38;5;241m=\u001b[39ms,\n\u001b[1;32m   3691\u001b[0m         c\u001b[38;5;241m=\u001b[39mc,\n\u001b[1;32m   3692\u001b[0m         marker\u001b[38;5;241m=\u001b[39mmarker,\n\u001b[1;32m   3693\u001b[0m         cmap\u001b[38;5;241m=\u001b[39mcmap,\n\u001b[1;32m   3694\u001b[0m         norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[1;32m   3695\u001b[0m         vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[1;32m   3696\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax,\n\u001b[1;32m   3697\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m   3698\u001b[0m         linewidths\u001b[38;5;241m=\u001b[39mlinewidths,\n\u001b[1;32m   3699\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39medgecolors,\n\u001b[1;32m   3700\u001b[0m         plotnonfinite\u001b[38;5;241m=\u001b[39mplotnonfinite,\n\u001b[1;32m   3701\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m   3702\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3703\u001b[0m     )\n\u001b[1;32m   3704\u001b[0m     sci(__ret)\n\u001b[1;32m   3705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_axes.py:4652\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4650\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[1;32m   4651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m-> 4652\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must be the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4655\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_internal.classic_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   4656\u001b[0m          mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines.markersize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "specific_track, lat, lon, SST, flu = zf.track_selector('20220203', zodiac_track_data, excludenans=True, excludemdr=True)\n",
    "\n",
    "plt.scatter(lon, lat, SST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ecf793a-ef66-43a0-9bef-b679e41a835a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6229"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19889e4c-08b9-432e-91c8-e4488233d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to fill #\n",
    "failed_dates   = [] # List of dates Zodiac did not leave\n",
    "zero_grad      = [] # indices of where a sst local max and min resides \n",
    "\n",
    "# Arrays for Data Analysis # \n",
    "filament_width = []\n",
    "symmetry       = []\n",
    "\n",
    "# Ensemble of ALL filaments #\n",
    "filament_ensemble = {}\n",
    "\n",
    "# Needed values #\n",
    "compass_range=np.arange(180, 361, 1)\n",
    "compass_range = np.append(compass_range, compass_range[::-1])\n",
    "\n",
    "# This master loop is simply to go through each possible date the zodiac went out, and grab corresponding data \n",
    "num = 0 # For counting fronts for our ensemble\n",
    "for d in range(len(dates)):\n",
    "    try: \n",
    "        # FUNCTION WILL GRAB DICTIONARY WITH CORREPSONDING DATE AND REMOVE NANS AS WELL AS ENSURE DATA IS IN DEFINED BOUNDS OF SMB - EXCLUDING MARINA\n",
    "        specific_track, lat, lon, SST, flu = zf.track_selector(dates[d], zodiac_track_data, excludenans=False, excludemdr=True)\n",
    "        # Data Processing, Filtering, & Gradients for SST #\n",
    "        dist_processed, sst_processed = zf.data_processing(lat, lon, SST, 10)\n",
    "        grad_dist_sst, grad_sst, lat_sst, lon_sst, sst_filtered, dist_filtered = \\\n",
    "        zf.running_avg_filter(window_size, lat, lon, sst_processed, dist_processed)\n",
    "        # Data Processing, Filtering, & Gradients for Flu #\n",
    "        dist_processed, flu_processed = zf.data_processing(lat, lon, flu, 10)\n",
    "        grad_dist_flu, grad_flu, grad_lat_flu, grad_lon_flu, flu_filtered, dist_filtered = \\\n",
    "        zf.running_avg_filter(window_size, lat, lon, flu_processed, dist_processed)\n",
    "\n",
    "        # Get final details on cruise path - Bearing (Direction of boat)\n",
    "        bearing = np.around(zf.bearing(lat_sst, lon_sst), 2)\n",
    "        # split this into components (vector form)\n",
    "        lon_comp = 1*np.sin(np.around(bearing, 0)*(np.pi/180))\n",
    "        lat_comp = 1*np.cos(np.around(bearing, 0)*(np.pi/180))\n",
    "                        \n",
    "        # Find the local SST minimum and maximums #\n",
    "        sst_loc_max, _ = find_peaks(sst_filtered, height=0) # READ ABOUT FIND PEAKS ####\n",
    "        sst_loc_min, _ = find_peaks(-1*sst_filtered, height = -30)\n",
    "        zero_grad = np.concatenate((sst_loc_max, sst_loc_min))\n",
    "        # Brefily ensure they are ordered, as the minumums and maximum indices are appended out of order (not along track...)\n",
    "        for i in range(0, len(zero_grad)):\n",
    "            for j in range(i+1, len(zero_grad)):\n",
    "                if(zero_grad[i] > zero_grad[j]):\n",
    "                    temp = zero_grad[i];\n",
    "                    zero_grad[i] = zero_grad[j];\n",
    "                    zero_grad[j] = temp;\n",
    "                    \n",
    "        # With our organized array of local maximum and minimum indices, we begin selecting individual segments\n",
    "        start = 0 # Begin at 0th index\n",
    "        for i in range(len(zero_grad)-1):    \n",
    "            # Filament #\n",
    "            end = start+1 # Index to next one over \n",
    "            index1, index2 = zero_grad[start], zero_grad[end] # index 1 and 2 are now the indices that define 1/2 a segment \n",
    "            start = end # Move start over 1 to grab next segment in loop\n",
    "\n",
    "            #print(f'Checking for Filament')\n",
    "            \n",
    "            # Check for Filament #\n",
    "            # Ensure that we start with a dip\n",
    "            if sst_filtered[index1] > sst_filtered[index2]:\n",
    "                # If true we become concerned in other portion, hence index 3, which is the peak following our central minima\n",
    "                index3 = zero_grad[end+1]\n",
    "                    \n",
    "                # Make sure that somewhere in our filament there is a sufficiently large gradient \n",
    "                #if np.max(grad_sst[index1:index2]) >= gradient_thresh and np.max(grad_sst[index2:index3]) >= gradient_thresh:\n",
    "                if (np.max(grad_sst[index1:index3]) >= gradient_thresh):\n",
    "                    \n",
    "                    # Check that we maintain a relatively straight bearing \n",
    "                    filament_xcomps, filament_ycomps = lon_comp[index1:index3], lat_comp[index1:index3]\n",
    "                    X, Y = lon_comp[index1], lat_comp[index1]\n",
    "                    angles = []\n",
    "                    for i in range(len(filament_xcomps)-1):\n",
    "                        try:\n",
    "                            xi, yi = filament_xcomps[i+1], filament_ycomps[i+1]\n",
    "                            angles = np.append(angles, (np.arccos(np.dot([X, Y], [xi, yi])/(np.sqrt(X**2 + Y**2)*np.sqrt(xi**2 + yi**2))))*(180/np.pi))\n",
    "                        except:\n",
    "                            angles = np.append(angles, np.mean(angles))\n",
    "                        continue\n",
    "                    # Ensure that heading does not change more than 90 deg\n",
    "                    if np.max(angles) < 90:    \n",
    "                        # Save Filament Data # \n",
    "                        filament_distance = dist_filtered[index1:index3]\n",
    "                        filament_sst      = sst_filtered[index1:index3]\n",
    "                        filament_flu      = flu_filtered[index1:index3]\n",
    "                        filament_lat      = lat_sst[index1:index3]\n",
    "                        filament_lon      = lon_sst[index1:index3]\n",
    "\n",
    "                        if normalize_ensembles == True:\n",
    "                        # ORGANIZE DATA #\n",
    "                        # order from 'small' to 'large' sides \n",
    "                            if filament_sst[-1] < filament_sst[0]:\n",
    "                                filament_sst = filament_sst[::-1]\n",
    "                                filament_flu = filament_flu[::-1]\n",
    "                            symm_test = (filament_sst[0]-np.min(filament_sst))/(filament_sst[-1]-np.min(filament_sst))\n",
    "                        else: \n",
    "                            if filament_sst[-1] < filament_sst[0]:\n",
    "                                symm_test = (filament_sst[-1]-np.min(filament_sst))/(filament_sst[0]-np.min(filament_sst))\n",
    "                            else:\n",
    "                                symm_test = (filament_sst[0]-np.min(filament_sst))/(filament_sst[-1]-np.min(filament_sst))\n",
    "                                \n",
    "                        # FINAL CHECKS - SYMMETRY AND DISCONTINUITIES #\n",
    "                        if (symm_test) >= .30:\n",
    "                            if len(np.diff(filament_distance)[np.diff(filament_distance) > 0.05]) == 0:\n",
    "\n",
    "                                # Normalize distances  \n",
    "                                index = np.where(filament_sst == np.min(filament_sst))\n",
    "                                min_index = index[0]\n",
    "                                equal_dist = filament_distance - filament_distance[min_index-1] # Equidistant View of Front from minima\n",
    "                                filament_width = np.append(filament_width, abs(equal_dist[0])+abs(equal_dist[-1])) # Single value for size of front\n",
    "        \n",
    "                                # SST # \n",
    "                                equal_sst = filament_sst - filament_sst[min_index]\n",
    "                                #prcnt_sst = ((filament_sst - filament_sst[0])/(filament_sst[-1] - filament_sst[0]))*100\n",
    "                                fil_symm = (filament_sst[0]-np.min(filament_sst))/(filament_sst[-1]-np.min(filament_sst))\n",
    "                                symmetry = np.append(symmetry, fil_symm)\n",
    "    \n",
    "                                # Positions of Filament (minima) #\n",
    "                                min_lat = filament_lat[min_index]\n",
    "                                min_lon = filament_lon[min_index]\n",
    "                                # Orientation of Filament #\n",
    "                                # x_comp  = filament_ycomps[min_index]\n",
    "                                # y_comp  = -1*filament_xcomps[min_index]\n",
    "                                x_comp  = np.mean(filament_ycomps)\n",
    "                                y_comp  = np.mean(-1*filament_xcomps)\n",
    "                                \n",
    "                                # Counter #\n",
    "                                fil_number = num+1\n",
    "                                num = fil_number\n",
    "                                print(f'Filament {fil_number} Detected on {dates[d]}', end = '\\r')\n",
    "        \n",
    "                                # Save to Dictionary # \n",
    "                                # Origin Based for Ensemble \n",
    "                                cruises = {'Date': (dates[d]), \\\n",
    "                                           # Filament Imaging\n",
    "                                           'Equi-Dist': (equal_dist), 'Equi-SST': (equal_sst), \\\n",
    "                                           # General Data\n",
    "                                           'Distance': (filament_distance), 'SST': (filament_sst), 'Flu': (filament_flu), \\\n",
    "                                           'Latitude': (filament_lat), 'Longitude': (filament_lon), \\\n",
    "                                           'Min-Lat': (min_lat), 'Min-Lon': (min_lon), \\\n",
    "                                           'x-comp': (x_comp), 'y-comp': (y_comp), \\\n",
    "                                           'Symmetry': (fil_symm)}\n",
    "                                filament_ensemble[str(fil_number)] = cruises\n",
    "\n",
    "                    \n",
    "    except:\n",
    "        failed_dates = np.append(failed_dates, dates[d])\n",
    "    continue "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d418b-186a-422e-8454-08fb2473e7e9",
   "metadata": {},
   "source": [
    "#### Fronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cbf00e-26bd-4bd3-9e90-208a86a1a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subset(arr1, arr2, m, n):\n",
    "\n",
    "    # Iterate over each element in the second array\n",
    "    for i in range(n):\n",
    "        found = False\n",
    "\n",
    "        # Check if the element exists in the first array\n",
    "        for j in range(m):\n",
    "            if arr2[i] == arr1[j]:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        # If any element is not found, return false\n",
    "        if not found:\n",
    "            return False\n",
    "\n",
    "    # If all elements are found, return true\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2f689-0eae-4679-92ac-f57d0ca14bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to fill #\n",
    "failed_dates = [] # List of dates Zodiac did not leave\n",
    "zero_grad = [] # indices of where a sst local max and min resides \n",
    "\n",
    "# Arrays for Data Analysis # \n",
    "front_width = []\n",
    "sst_change = []\n",
    "\n",
    "# Ensemble of ALL Fronts #\n",
    "front_ensemble = {}\n",
    "\n",
    "# This master loop is simply to go through each possible date the zodiac went out, and grab corresponding data \n",
    "num = 0 # For counting fronts for our ensemble\n",
    "for d in range(len(dates)):\n",
    "    try: \n",
    "        # FUNCTION WILL GRAB DICTIONARY WITH CORREPSONDING DATE AND REMOVE NANS AS WELL AS ENSURE DATA IS IN DEFINED BOUNDS OF SMB - EXCLUDING MARINA\n",
    "        specific_track, lat, lon, SST, flu = zf.track_selector(dates[d], zodiac_track_data, excludenans=True, excludemdr=True)\n",
    "        \n",
    "        # Data Processing, Filtering, & Gradients for SST #\n",
    "        dist_processed, sst_processed = zf.data_processing(lat, lon, SST, 10)\n",
    "        grad_dist_sst, grad_sst, lat_sst, lon_sst, sst_filtered, dist_filtered = \\\n",
    "        zf.running_avg_filter(window_size, lat, lon, sst_processed, dist_processed)\n",
    "        # Data Processing, Filtering, & Gradients for Flu #\n",
    "        dist_processed, flu_processed = zf.data_processing(lat, lon, flu, 10)\n",
    "        grad_dist_flu, grad_flu, grad_lat_flu, grad_lon_flu, flu_filtered, dist_filtered = \\\n",
    "        zf.running_avg_filter(window_size, lat, lon, flu_processed, dist_processed)\n",
    "        \n",
    "        # Find the local SST minimum and maximums #\n",
    "        sst_loc_max, _ = find_peaks(sst_filtered, height=0)\n",
    "        sst_loc_min, _ = find_peaks(-1*sst_filtered, height = -30)\n",
    "        zero_grad = np.concatenate((sst_loc_max, sst_loc_min))\n",
    "        # Brefily ensure they are ordered, as the minumums and maximums are concated out of order (not along track...)\n",
    "        for i in range(0, len(zero_grad)):\n",
    "            for j in range(i+1, len(zero_grad)):\n",
    "                if(zero_grad[i] > zero_grad[j]):\n",
    "                    temp = zero_grad[i];\n",
    "                    zero_grad[i] = zero_grad[j];\n",
    "                    zero_grad[j] = temp;\n",
    "                    \n",
    "        # With our organized array of local maximum and minimums, we begin selecting individual segments\n",
    "        start = 0 # Begin at 0th index\n",
    "        for i in range(len(zero_grad)-1):\n",
    "            end = start+1 # Index to next one over \n",
    "            index1, index2 = zero_grad[start], zero_grad[end] # index 1 and 2 are now the indices that define one segment \n",
    "            start = end # Move start over 1 to grab next segment in loop\n",
    "            \n",
    "            # With an individual segment selected, we grab its gradients and check whether it is a front via boolean # \n",
    "            nonzero_gradients = grad_sst[index1:index2]\n",
    "            if np.max(nonzero_gradients) >= gradient_thresh: # since the front is of a large degree change, save its distance\n",
    "                \n",
    "                # Here, it has been proven that our segment exceeds a set threshold, and is indeed a front. Therefore grab other variables  \n",
    "                nonzero_gradient_distances = grad_dist_sst[index1:index2] # Coordinates for gradient locations \n",
    "                frontal_distance = dist_filtered[index1:index2] # coordinates for sst and flu locations \n",
    "                frontal_sst = sst_filtered[index1:index2]\n",
    "                frontal_flu = flu_filtered[index1:index2]\n",
    "                # Record the position too, using boat positions \n",
    "                front_lat = lat_sst[index1:index2]\n",
    "                front_lon = lon_sst[index1:index2]\n",
    "                \n",
    "                # Ensure that this front is not a part of a filament\n",
    "                filament = 0\n",
    "                for f in range(len(filament_ensemble)):\n",
    "                    if (filament_ensemble[str(f+1)]['Date'] == dates[d]):\n",
    "                        fil_lat = filament_ensemble[str(f+1)]['Latitude']\n",
    "                        fil_lon = filament_ensemble[str(f+1)]['Longitude']\n",
    "                        if is_subset(fil_lat, front_lat, len(fil_lat), len(front_lat)) and is_subset(fil_lon, front_lon, len(fil_lon), len(front_lon)):\n",
    "                            #print(f'{dates[d]} number {(f)} is a filament')\n",
    "                            filament = 1\n",
    "                            break\n",
    "                if filament != 1:\n",
    "                    \n",
    "                    # We have a front and relevant information about that front. Before we proceed, lets make sure this front is 'legit' #\n",
    "                    # in some cases, data outages may creates large gaps in data, placing two different water readings next to each other \n",
    "                    if len(np.diff(frontal_distance)[np.diff(frontal_distance) > 0.05]) == 0:\n",
    "                        # If there is not a large discontinuity across the bay, ensure that the removal of the marina has not created its own gap\n",
    "                        mdr_front_lat = front_lat[((front_lon > -118.481) & (front_lon < -118.418)) & ((front_lat < 33.984) & (front_lat > 33.936))]\n",
    "                        mdr_front_lon = front_lon[((front_lon > -118.481) & (front_lon < -118.418)) & ((front_lat < 33.984) & (front_lat > 33.936))]\n",
    "                        # if there is data right outside of marina we exclude these fronts from the data, such that the loop does not conitnue\n",
    "                        if (len(mdr_front_lat) == 0 ) and (len(mdr_front_lon) == 0):\n",
    "                            \n",
    "                            # Organize from cold to warm water, if not already, such that all fronts are interpreted along one direction #\n",
    "                            if normalize_ensembles == True:\n",
    "                                if frontal_sst[-1] < frontal_sst[0]:\n",
    "                                    frontal_sst = frontal_sst[::-1]\n",
    "                                    frontal_flu = frontal_flu[::-1]\n",
    "                                # Distances direction is irrelevant, start with collecting normalized data \n",
    "                                \n",
    "                            # Distances \n",
    "                            mid_index = int(len(frontal_distance)/2)\n",
    "                            equal_dist = frontal_distance - frontal_distance[mid_index-1] # Equidistant View of Front, for common origin in ensemble\n",
    "                            prcnt_dist = ((frontal_distance - frontal_distance[0])/(frontal_distance[-1] - frontal_distance[0]))*100 # Front length in %\n",
    "                            front_width = np.append(front_width, abs(equal_dist[0])+abs(equal_dist[-1])) # Single value for size of front\n",
    "                        \n",
    "                            # SST \n",
    "                            equal_sst = frontal_sst - frontal_sst[mid_index]\n",
    "                            prcnt_sst = ((frontal_sst - frontal_sst[0])/(frontal_sst[-1] - frontal_sst[0]))*100\n",
    "                            sst_change = np.append(sst_change, frontal_sst[-1]-frontal_sst[0]) \n",
    "    \n",
    "                            # Counter #\n",
    "                            front_number = num+1\n",
    "                            num = front_number\n",
    "                            print(f'Front {front_number} Detected on {dates[d]}', end = '\\r')\n",
    "                            \n",
    "                            \n",
    "                            # Save to Dictionary # \n",
    "                                      # Origin Based for Ensemble \n",
    "                            cruises = {'Date': (dates[d]), \\\n",
    "                                       # Frontal Imaging\n",
    "                                       'Equi-Dist': (equal_dist), 'Equi-SST': (equal_sst), \\\n",
    "                                       # General Data\n",
    "                                       'Distance': (frontal_distance), 'SST': (frontal_sst), 'Flu': (frontal_flu)}\n",
    "                            front_ensemble[str(front_number)] = cruises\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        failed_dates = np.append(failed_dates, dates[d])\n",
    "    continue "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c03542-e572-45c6-b5d2-3b93deea949e",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b03cb2-53e8-45d4-b4db-9f6f0e7d4d79",
   "metadata": {},
   "source": [
    "#### Individual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345e811-39fe-40ef-93c8-89c0a29daf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if individual_cruise_ensemble == True:\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize = (20,10))\n",
    "    #date = '010115'\n",
    "    #res = 70\n",
    "    \n",
    "    plt.plot(dist_filtered, sst_filtered)\n",
    "    bearing = np.around(zf.bearing(lat_sst, lon_sst), 2)\n",
    "    # split this into components (vector form)\n",
    "    lon_comp = 1*np.sin(np.around(bearing, 0)*(np.pi/180))\n",
    "    lat_comp = 1*np.cos(np.around(bearing, 0)*(np.pi/180))\n",
    "    #plt.quiver(dist_filtered[::res], np.mean(sst_filtered)*np.ones(len(dist_filtered))[::res], lon_comp[::res], lat_comp[::res], \\\n",
    "           #headwidth = .1)\n",
    "    #plt.scatter(dist_filtered, np.min(sst_filtered)*np.ones(len(dist_filtered)) - .01*np.min(sst_filtered), c = bearing, \\\n",
    "                #s = 1000, marker='s', cmap='twilight_shifted')\n",
    "\n",
    "    x = dist_filtered\n",
    "    z = bearing \n",
    "    y = np.min(sst_filtered)*np.ones(len(dist_filtered)) - .01*np.min(sst_filtered)\n",
    "    \n",
    "    # Sort the x values and corresponding z values\n",
    "    sorted_indices = np.argsort(x)\n",
    "    x_sorted = x[sorted_indices]\n",
    "    z_sorted = z[sorted_indices]\n",
    "    \n",
    "    # Create segments for the line\n",
    "    points = np.array([x_sorted, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    \n",
    "    # Normalize colors for the colormap\n",
    "    norm = plt.Normalize(z_sorted.min(), z_sorted.max())\n",
    "    cmap = plt.cm.twilight_shifted # Choose a colormap\n",
    "    \n",
    "    # Create a LineCollection\n",
    "    line_collection = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "    line_collection.set_array(z_sorted[:-1])  # Set colors based on z values\n",
    "    line_collection.set_linewidth(30)  # Set thickness of the line\n",
    "\n",
    "    ax.add_collection(line_collection)\n",
    "        \n",
    "    for i in range(len(filament_ensemble)):\n",
    "        x=filament_ensemble[str(i+1)]['Distance']\n",
    "        y=filament_ensemble[str(i+1)]['SST']    \n",
    "        plt.plot(x, y, '-g')\n",
    "    # for i in range(len(front_ensemble)):\n",
    "    #     x=front_ensemble[str(i+1)]['Distance']\n",
    "    #     y=front_ensemble[str(i+1)]['SST']\n",
    "    #     plt.plot(x, y, '-r')\n",
    "    \n",
    "    #plt.colorbar().set_label('Boat Heading - North = 0/360$^{\\circ}$', fontsize = fs_tick)\n",
    "    # Add a colorbar\n",
    "    cbar = fig.colorbar(line_collection, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Boat Heading - North = 0/360$^{\\circ}$', fontsize = fs_tick)\n",
    "    \n",
    "    # Plot discontinuities \n",
    "    dist_track = []\n",
    "    if len(np.diff(dist_filtered)[np.diff(dist_filtered) > 0.05]) != 0:\n",
    "        breaks = np.where(np.diff(dist_filtered) > 0.05)[0]\n",
    "        start = 0\n",
    "        for b in range(len(breaks)):\n",
    "            dist_track.append(dist_filtered[start:breaks[b]+1])\n",
    "            start = breaks[b]+1\n",
    "            if (b+1) == len(breaks):\n",
    "                dist_track.append(dist_filtered[start::])\n",
    "    for n in range(len(dist_track)): \n",
    "        if (n > 0) and (n < len(dist_track)):\n",
    "            plt.axvspan(dist_track[n-1][-1], dist_track[n][0], color = 'gray', zorder = 0)\n",
    "\n",
    "    green_patch = mpatches.Patch(color='green', label='Filament') \n",
    "    red_patch = mpatches.Patch(color='red', label='Front')\n",
    "    gray_patch = mpatches.Patch(color='gray', label='Discontinuity')\n",
    "    plt.legend(handles=[green_patch, red_patch, gray_patch], loc='upper right', fontsize = fs_tick)\n",
    "    \n",
    "    plt.xticks(fontsize=fs_tick)\n",
    "    plt.yticks(fontsize=fs_tick)\n",
    "        \n",
    "    plt.title('Filaments versus Fronts in SST Track', fontsize=fs_title)\n",
    "    plt.xlabel('Distance [km]', fontsize = fs_label)\n",
    "    plt.ylabel('SST [$^{\\circ}C$]', fontsize = fs_label)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "if saveplots == True:\n",
    "    plt.savefig('individual_cruise.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8543500-5d9f-4eb2-833e-9997e7737a64",
   "metadata": {},
   "source": [
    "#### Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c06db-6ed3-4dca-8be2-219b17f62f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_ens_fig = plt.figure(1, (20, 10)) \n",
    "date = []\n",
    "\n",
    "for i in range(len(filament_ensemble)):\n",
    "    sum = (i+1)\n",
    "    x = filament_ensemble[str(i+1)]['Equi-Dist']\n",
    "    y = filament_ensemble[str(i+1)]['Equi-SST']\n",
    "    date = np.append(date, filament_ensemble[str(i+1)]['Date'])\n",
    "    \n",
    "    # if showFlu == True:\n",
    "    #     f = filament_ensemble[str(i)]['Flu']\n",
    "    #     plt.plot(x, f)\n",
    "\n",
    "    if max(y) <= .5:\n",
    "        plt.plot(x, y, color = 'green', zorder=4)\n",
    "    elif max(y) <= 1.0:\n",
    "        plt.plot(x, y, color = 'blue', zorder=3)\n",
    "    elif max(y) <= 1.5:\n",
    "        plt.plot(x, y, color = 'orange', zorder=2)\n",
    "    else:\n",
    "        plt.plot(x, y, color = 'red', zorder=1)\n",
    "\n",
    "    plt.xlabel('Distance from Minimum SST [km]', fontsize=fs_label)\n",
    "    plt.ylabel('$\\Delta$SST from Minimum [$^{\\circ}C$]', fontsize=fs_label)\n",
    "    plt.title(f'Ensemble of Filaments - {sum} Total', fontsize=fs_title)\n",
    "\n",
    "dates = np.unique(date)\n",
    "\n",
    "plt.xticks(fontsize=fs_tick), plt.yticks(fontsize=fs_tick)\n",
    "\n",
    "green_patch = mpatches.Patch(color='green', label='$\\Delta_{max}$ $\\leq$ .5') \n",
    "blue_patch = mpatches.Patch(color='blue', label='.5 < $\\Delta_{max}$ $\\leq$ 1.0')\n",
    "orange_patch = mpatches.Patch(color='orange', label='1.0 < $\\Delta_{max}$ $\\leq$ 1.5')\n",
    "red_patch = mpatches.Patch(color='red', label='$\\Delta_{max}$ > 1.5')\n",
    "plt.legend(handles=[green_patch, blue_patch, orange_patch, red_patch], fontsize = 20)\n",
    "\n",
    "plt.axhline(y=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "plt.axvline(x=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(f'Cruise Dates: \\n {dates}')\n",
    "\n",
    "# if saveplots == True:\n",
    "#     plt.savefig('all_filament_ensemble.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5379e1-b176-4744-8198-615ccab59e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41e9e18-df23-4fd8-9439-8447199ca41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "front_ens_fig = plt.figure(1, (20, 10)) \n",
    "date = []\n",
    "legend_settings = 'sst_change'\n",
    "\n",
    "sum = 0\n",
    "for i in range(len(front_ensemble)):\n",
    "    x = front_ensemble[str(i+1)]['Equi-Dist']\n",
    "    y = front_ensemble[str(i+1)]['Equi-SST']\n",
    "    date = np.append(date, front_ensemble[str(i+1)]['Date'])\n",
    "    if front_width[i] <= .5:\n",
    "        sum = sum + 1\n",
    "        plt.plot(x, y, color = 'green', zorder=4)\n",
    "    elif front_width[i] <= 1.0:\n",
    "        sum = sum + 1\n",
    "        plt.plot(x, y, color = 'blue', zorder=3)\n",
    "    elif front_width[i] <= 1.5:\n",
    "        sum = sum + 1\n",
    "        plt.plot(x, y, color = 'orange', zorder=2)\n",
    "\n",
    "dates = np.unique(date)\n",
    "\n",
    "green_patch = mpatches.Patch(color='green', label='$Width \\leq .5km$') \n",
    "blue_patch = mpatches.Patch(color='blue', label='.5km < $Width$ $\\leq$ 1.0km')\n",
    "orange_patch = mpatches.Patch(color='orange', label='1.0km < $Width$ $\\leq$ 1.5km')\n",
    "\n",
    "    \n",
    "plt.legend(handles=[green_patch, blue_patch, orange_patch], fontsize = 20)\n",
    "\n",
    "plt.xticks(fontsize=fs_tick), plt.yticks(fontsize=fs_tick)\n",
    "                \n",
    "plt.xlabel('Distance from Midpoint [km]', fontsize=fs_label)\n",
    "plt.ylabel('$\\Delta$SST from Midpoint [$^{\\circ}C$]', fontsize=fs_label)\n",
    "plt.title(f'Ensemble of Fronts - {sum} Total', fontsize=fs_title)\n",
    "\n",
    "plt.axhline(y=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "plt.axvline(x=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "\n",
    "plt.xlim(-.75, .75)\n",
    "plt.ylim(-3, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if saveplots == True:\n",
    "    plt.savefig('all_fronts_ensemble.png')\n",
    "\n",
    "print(f'Cruise Dates: \\n {dates}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bea724-7b45-4d28-809e-261fa79cd0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "front_ens_fig = plt.figure(1, (20, 10)) \n",
    "date = []\n",
    "legend_settings = 'sst_change'\n",
    "\n",
    "sum = 0\n",
    "for i in range(len(front_ensemble)):\n",
    "    x = front_ensemble[str(i+1)]['Equi-Dist']\n",
    "    y = front_ensemble[str(i+1)]['Equi-SST']\n",
    "    if front_width[i] > 5:\n",
    "        continue\n",
    "    date = np.append(date, front_ensemble[str(i+1)]['Date'])\n",
    "    sum = i + 1\n",
    "    if legend_settings == 'width':\n",
    "        if front_width[i] <= .5:\n",
    "            plt.plot(x, y, color = 'green', zorder=4)\n",
    "        elif front_width[i] <= 1.0:\n",
    "            plt.plot(x, y, color = 'blue', zorder=3)\n",
    "        elif front_width[i] <= 1.5:\n",
    "            plt.plot(x, y, color = 'orange', zorder=2)\n",
    "        else:\n",
    "            plt.plot(x, y, color = 'red', zorder=1)\n",
    "    else:\n",
    "        if sst_change[i] <= .5:\n",
    "            plt.plot(x, y, color = 'green', zorder=4)\n",
    "        elif sst_change[i] <= 1:\n",
    "            plt.plot(x, y, color = 'blue', zorder=3)\n",
    "        elif sst_change[i] <= 1.5:\n",
    "            plt.plot(x, y, color = 'orange', zorder=2)\n",
    "        else:\n",
    "            plt.plot(x, y, color = 'red', zorder=1)\n",
    "\n",
    "dates = np.unique(date)\n",
    "\n",
    "if legend_settings == 'width':\n",
    "    green_patch = mpatches.Patch(color='green', label='$Width \\leq .5km$') \n",
    "    blue_patch = mpatches.Patch(color='blue', label='.5km < $Width$ $\\leq$ 1.0km')\n",
    "    orange_patch = mpatches.Patch(color='orange', label='1.0km < $Width$ $\\leq$ 1.5km')\n",
    "    red_patch = mpatches.Patch(color='red', label='$Width$ > 1.5km')\n",
    "    plt.legend(handles=[green_patch, blue_patch, orange_patch, red_patch], fontsize = 20)\n",
    "else:\n",
    "    green_patch = mpatches.Patch(color='green', label='$\\Delta_{sst} \\leq .5^{\\circ}C$') \n",
    "    blue_patch = mpatches.Patch(color='blue', label='$.5^{\\circ}C$ < $\\Delta_{sst}$ $\\leq$ 1.0$^{\\circ}C$')\n",
    "    orange_patch = mpatches.Patch(color='orange', label='$1.0^{\\circ}C$ < $\\Delta_{sst}$ $\\leq$ $1.5^{\\circ}C$')\n",
    "    red_patch = mpatches.Patch(color='red', label='$\\Delta_{sst}$ > $1.5^{\\circ}C$')\n",
    "    plt.legend(handles=[green_patch, blue_patch, orange_patch, red_patch], fontsize = 20)\n",
    "\n",
    "plt.xticks(fontsize=fs_tick), plt.yticks(fontsize=fs_tick)\n",
    "                \n",
    "plt.xlabel('Distance from Midpoint [km]', fontsize=fs_label)\n",
    "plt.ylabel('$\\Delta$SST from Midpoint [$^{\\circ}C$]', fontsize=fs_label)\n",
    "plt.title(f'Ensemble of Fronts - {sum} Total', fontsize=fs_title)\n",
    "\n",
    "plt.axhline(y=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "plt.axvline(x=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "\n",
    "plt.xlim(-2.75, 2.75)\n",
    "plt.ylim(-3, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(f'Cruise Dates: \\n {dates}')\n",
    "\n",
    "if saveplots == True:\n",
    "    plt.savefig('all_fronts_ensemble.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863090fe-ccdb-4155-9c3f-74c36de040f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Fluorometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090175a-9582-4a7e-8ad4-4ad235ae8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if individual_cruise_ensemble == True:\n",
    "\n",
    "    from statistics import covariance\n",
    "    fig, ax1 = plt.subplots(1, figsize = (20,10))\n",
    "    ax2 = ax1.twinx()\n",
    "    #date = '010115'\n",
    "    #res = 70\n",
    "\n",
    "    cov_fil,  r_fil  = [], []\n",
    "    cov_data, r_data = [], []\n",
    "\n",
    "    fil_sst, fil_flu = [], []\n",
    "    non_sst, non_flu = [], [] \n",
    "    \n",
    "    ax1.plot(dist_filtered, sst_filtered, color = 'lightcoral')\n",
    "    ax2.plot(dist_filtered, flu_filtered, color = 'seagreen')\n",
    "\n",
    "    all_fil_din = []\n",
    "    for i in range(len(filament_ensemble)):\n",
    "        x=filament_ensemble[str(i+1)]['Distance']\n",
    "        y=filament_ensemble[str(i+1)]['SST']\n",
    "        z=filament_ensemble[str(i+1)]['Flu']\n",
    "\n",
    "        # current fil\n",
    "        cov_fil = np.append(cov_fil, np.abs(covariance(y,z))/(np.std(y)*np.std(z)))\n",
    "        r_fil   = np.append(r_fil,   np.abs(ss.pearsonr(y,z)[0]))\n",
    "        fil_sst = np.append(fil_sst, y)\n",
    "        fil_flu = np.append(fil_flu, z)\n",
    "        \n",
    "        ax1.axvspan(x[0], x[-1], color = 'gray', alpha = .1, zorder = 0)\n",
    "        ax1.axvline(x[0], color ='k', linestyle = '--', alpha = .7)\n",
    "        ax1.axvline(x[-1], color = 'k', linestyle = '--', alpha = .7)\n",
    "\n",
    "        # Not in fil\n",
    "        fil_dis_str = int(np.where(dist_filtered == x[0])[0][0])\n",
    "        fil_dis_end = int(np.where(dist_filtered == x[-1])[0][0])\n",
    "        if i == 0:\n",
    "            #ax1.axvspan(0, dist_filtered[fil_dis_str], color = 'blue', alpha = .1, zorder = 0)\n",
    "            nx = dist_filtered[0:fil_dis_str]\n",
    "            ny = sst_filtered[0:fil_dis_str]\n",
    "            nz = flu_filtered[0:fil_dis_str]\n",
    "        elif i == (len(filament_ensemble)-1):\n",
    "            #ax1.axvspan(dist_filtered[fil_dis_end], dist_filtered[-1], color = 'blue', alpha = .1, zorder = 0)\n",
    "            nx = dist_filtered[fil_dis_end+1:-1]\n",
    "            ny = sst_filtered[fil_dis_end+1:-1]\n",
    "            nz = flu_filtered[fil_dis_end+1:-1]\n",
    "        else:\n",
    "            d=filament_ensemble[str(i)]['Distance']\n",
    "            old_dis_end = int(np.where(dist_filtered == d[-1])[0][0])\n",
    "            #ax1.axvspan(dist_filtered[old_dis_end], dist_filtered[fil_dis_str], color = 'blue', alpha = .1, zorder = 0)\n",
    "            nx = dist_filtered[old_dis_end+1:fil_dis_str-1]\n",
    "            ny = sst_filtered[old_dis_end+1:fil_dis_str-1]\n",
    "            nz = flu_filtered[old_dis_end+1:fil_dis_str-1]\n",
    "\n",
    "        non_sst = np.append(non_sst, ny)\n",
    "        non_flu = np.append(non_flu, nz)\n",
    "        \n",
    "        cov_data = np.append(cov_data, np.abs(covariance(ny,nz))/(np.std(ny)*np.std(nz)))\n",
    "        r_data   = np.append(r_data,   np.abs(ss.pearsonr(ny,nz)[0]))\n",
    "        \n",
    "        # ax1.plot(nx, ny, color = 'm')\n",
    "        # ax2.plot(nx, nz, color = 'm')\n",
    "\n",
    "    for i in range(len(front_ensemble)):\n",
    "        x=front_ensemble[str(i+1)]['Distance']\n",
    "        y=front_ensemble[str(i+1)]['SST']\n",
    "\n",
    "    # r vals\n",
    "    # cov_filament  = np.mean(cov_fil)\n",
    "    # r_filament    = np.mean(r_fil)\n",
    "    # cov_nofill = np.mean(cov_data)\n",
    "    # r_nofill   = np.mean(r_data)\n",
    "\n",
    "    cov_filament  = np.abs(covariance(fil_sst,fil_flu))/(np.std(fil_sst)*np.std(fil_flu))\n",
    "    r_filament    = np.abs(ss.pearsonr(fil_sst,fil_flu)[0])\n",
    "    cov_nofill = np.abs(covariance(non_sst,non_flu))/(np.std(non_sst)*np.std(non_flu))\n",
    "    r_nofill   = np.abs(ss.pearsonr(non_sst,non_flu)[0])\n",
    "    \n",
    "    print(cov_filament, r_filament)\n",
    "    print(cov_nofill, r_nofill)\n",
    "    \n",
    "    # Plot discontinuities \n",
    "    dist_track = []\n",
    "    if len(np.diff(dist_filtered)[np.diff(dist_filtered) > 0.05]) != 0:\n",
    "        breaks = np.where(np.diff(dist_filtered) > 0.05)[0]\n",
    "        start = 0\n",
    "        for b in range(len(breaks)):\n",
    "            dist_track.append(dist_filtered[start:breaks[b]+1])\n",
    "            start = breaks[b]+1\n",
    "            if (b+1) == len(breaks):\n",
    "                dist_track.append(dist_filtered[start::])\n",
    "    for n in range(len(dist_track)): \n",
    "        if (n > 0) and (n < len(dist_track)):\n",
    "            plt.axvspan(dist_track[n-1][-1], dist_track[n][0], color = 'gray', zorder = 0)\n",
    "\n",
    "    \n",
    "    gray_patch = mpatches.Patch(color='gray', label='Span of Filament')\n",
    "    leg = plt.legend(handles=[ gray_patch], loc='upper right', fontsize = fs_tick)\n",
    "    frame = leg.get_frame()\n",
    "    frame.set_linewidth(1)\n",
    "    frame.set_edgecolor('black')\n",
    "    \n",
    "    # ax1.set_xticks(fontsize=fs_tick)\n",
    "    # ax1.set_yticks(fontsize=fs_tick)\n",
    "    # ax2.set_yticks(fontsize=fs_tick)\n",
    "\n",
    "    ax1.tick_params(axis='x', labelsize=fs_tick)\n",
    "    ax1.tick_params(axis='y', labelsize=fs_tick, colors='lightcoral')\n",
    "    ax2.tick_params(axis='y', labelsize=fs_tick, colors='seagreen')\n",
    "\n",
    "    ax1.set_title('Variance in Fluorescence with Temperature - August 17$^{th}$, 2020', fontsize=fs_title)\n",
    "    ax1.set_xlabel('Distance (km)', fontsize = fs_label)\n",
    "    ax1.set_ylabel('SST ($^{\\circ}$C)', fontsize = fs_label, color = 'lightcoral')\n",
    "    ax2.set_ylabel('Fluorescence (counts)', fontsize = fs_label, color = 'seagreen')\n",
    "\n",
    "    ax1.text(0, 21.5, f'$r_{{filament}}: {r_filament:.3f}$', fontsize=fs_tick)\n",
    "    ax1.text(0,21.3, f'$r_{{nofil.}}   :{r_nofill:.3f}$', fontsize=fs_tick)\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "if saveplots == True:\n",
    "    plt.savefig('flu_cruisetrack.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4e5f8-d83e-436e-92e7-fa727cf70a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(zf.gradient(dist_filtered, sst_filtered, lat_sst, lon_sst)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f645352-261a-44f9-a34d-b98750b1e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(sst_filtered)-np.min(sst_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2f6e1-7522-4752-a8dd-93637f09ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_filtered[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00bf918-d3b1-4d63-9729-ea7c58d4d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_ens_fig, ax1 = plt.subplots(1, figsize = (20, 10)) \n",
    "date = []\n",
    "ax2 = ax1.twinx()\n",
    "showFlu = True\n",
    "\n",
    "for i in range(len(filament_ensemble)):\n",
    "    sum = (i+1)\n",
    "    x = filament_ensemble[str(i+1)]['Equi-Dist']\n",
    "    y = filament_ensemble[str(i+1)]['Equi-SST']\n",
    "    date = np.append(date, filament_ensemble[str(i+1)]['Date'])\n",
    "    if showFlu == True:\n",
    "        f = filament_ensemble[str(i+1)]['Flu']\n",
    "        f_norm = ((f - np.min(f))/(np.max(f)-np.min(f)))*100\n",
    "\n",
    "    ax1.plot(x, y, 'lightcoral', alpha = .8)\n",
    "    ax2.plot(x, f_norm, 'seagreen', alpha = .4)\n",
    "    ax1.set_zorder(ax2.get_zorder()+1)\n",
    "    ax1.patch.set_visible(False)\n",
    "\n",
    "ax1.set_xlabel('Distance from Minimum SST [km]', fontsize=fs_label)\n",
    "ax1.set_ylabel('$\\Delta$SST from Minimum [$^{\\circ}C$]', fontsize=fs_label)\n",
    "ax1.set_title(f'Ensemble of Filaments with Fluorometry - {sum} Total', fontsize=fs_title)\n",
    "\n",
    "dates = np.unique(date)\n",
    "\n",
    "#plt.xticks(fontsize=fs_tick), plt.yticks(fontsize=fs_tick)\n",
    "\n",
    "green_patch = mpatches.Patch(color='green', label='Fluorescence')\n",
    "red_patch = mpatches.Patch(color='red', label='SST')\n",
    "ax1.legend(handles=[green_patch, red_patch], fontsize = 20)\n",
    "\n",
    "# plt.axhline(y=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "# plt.axvline(x=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "print(f'Cruise Dates: \\n {dates}')\n",
    "\n",
    "plt.savefig('filament_flu_ensemble.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfbf5fa-5b5d-4364-b44e-bd3ca0a6351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_ens_fig, ax1 = plt.subplots(1, figsize = (20, 10)) \n",
    "date = []\n",
    "ax2 = ax1.twinx()\n",
    "showFlu = True\n",
    "\n",
    "for i in range(len(front_ensemble)):\n",
    "    sum = (i+1)\n",
    "    x = front_ensemble[str(i+1)]['Equi-Dist']\n",
    "    y = front_ensemble[str(i+1)]['Equi-SST']\n",
    "    if front_width[i] > 5:\n",
    "        continue\n",
    "    date = np.append(date, front_ensemble[str(i+1)]['Date'])\n",
    "    if showFlu == True:\n",
    "        f = front_ensemble[str(i+1)]['Flu']\n",
    "        f_norm = ((f - np.min(f))/(np.max(f)-np.min(f)))*100\n",
    "\n",
    "    ax1.plot(x, y, 'lightcoral', alpha = .8)\n",
    "    ax2.plot(x, f_norm, 'seagreen', alpha = .4)\n",
    "    ax1.set_zorder(ax2.get_zorder()+1)\n",
    "    ax1.patch.set_visible(False)\n",
    "\n",
    "ax1.set_xlabel('Distance from Midpoint [km]', fontsize=fs_label)\n",
    "ax1.set_ylabel('$\\Delta$SST from Midpoint [$^{\\circ}C$]', fontsize=fs_label)\n",
    "ax1.set_title(f'Ensemble of Fronts with Fluorometry - {sum} Total', fontsize=fs_title)\n",
    "\n",
    "dates = np.unique(date)\n",
    "\n",
    "#plt.xticks(fontsize=fs_tick), plt.yticks(fontsize=fs_tick)\n",
    "\n",
    "green_patch = mpatches.Patch(color='green', label='Fluorescence')\n",
    "red_patch = mpatches.Patch(color='red', label='SST')\n",
    "ax1.legend(handles=[green_patch, red_patch], fontsize = 20)\n",
    "\n",
    "# plt.axhline(y=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "# plt.axvline(x=0, linestyle = '--', color = 'k', alpha = .5)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "print(f'Cruise Dates: \\n {dates}')\n",
    "\n",
    "plt.savefig('fronts_flu_ensemble.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ec336-24d0-44ef-af07-c900bc44c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "titles = ['$Width \\leq .5km$', '.5km < $Width$ $\\leq$ 1.0km', '1.0km < $Width$ $\\leq$ 1.5km', '$Width$ > 1.5km']\n",
    "\n",
    "for i in range(len(front_ensemble)):\n",
    "    sum = (i+1)\n",
    "    x = front_ensemble[str(i+1)]['Equi-Dist']\n",
    "    y = front_ensemble[str(i+1)]['Equi-SST']\n",
    "    f = front_ensemble[str(i+1)]['Flu']\n",
    "    f_norm = ((f - np.min(f))/(np.max(f)-np.min(f)))*100\n",
    "    if front_width[i] > 5:\n",
    "        continue\n",
    "    if front_width[i] <= .5:\n",
    "        # Subplot 1\n",
    "        ax1 = axs[0, 0]\n",
    "        ax1.plot(x, y, color='lightcoral', alpha = .4, zorder = 1)\n",
    "        ax1.set_ylabel('$\\Delta$SST', color='lightcoral')\n",
    "        ax1.tick_params(axis='y', labelcolor='lightcoral')\n",
    "        \n",
    "        ax1_twin = ax1.twinx()\n",
    "        ax1_twin.plot(x, f_norm, color='seagreen', alpha = .4, zorder = 2)\n",
    "        ax1_twin.set_ylabel('Fluorometry', color='seagreen')\n",
    "        ax1_twin.tick_params(axis='y', labelcolor='seagreen')\n",
    "        ax1.set_title(titles[0])\n",
    "\n",
    "        ax1.set_xlabel('Distance from Midpoint [km]')\n",
    "    elif front_width[i] <= 1.0:\n",
    "        # Subplot 2\n",
    "        ax2 = axs[0, 1]\n",
    "        ax2.plot(x, y, color='lightcoral', alpha = .4, zorder = 1)\n",
    "        ax2.set_ylabel('$\\Delta$SST', color='lightcoral')\n",
    "        ax2.tick_params(axis='y', labelcolor='lightcoral')\n",
    "        \n",
    "        ax2_twin = ax2.twinx()\n",
    "        ax2_twin.plot(x, f_norm, color='seagreen', alpha = .4, zorder = 2)\n",
    "        ax2_twin.set_ylabel('Fluorometry', color='seagreen')\n",
    "        ax2_twin.tick_params(axis='y', labelcolor='seagreen')\n",
    "        ax2.set_title(titles[1])\n",
    "            \n",
    "        ax2.set_xlabel('Distance from Midpoint [km]')\n",
    "    elif front_width[i] <= 1.5:\n",
    "        # Subplot 3\n",
    "        ax3 = axs[1, 0]\n",
    "        ax3.plot(x, y, color='lightcoral', alpha = .4, zorder = 1)\n",
    "        ax3.set_ylabel('$\\Delta$SST', color='lightcoral')\n",
    "        ax3.tick_params(axis='y', labelcolor='lightcoral')\n",
    "        \n",
    "        ax3_twin = ax3.twinx()\n",
    "        ax3_twin.plot(x, f_norm, color='seagreen', alpha = .4, zorder = 2)\n",
    "        ax3_twin.set_ylabel('Fluorometry', color='seagreen')\n",
    "        ax3_twin.tick_params(axis='y', labelcolor='seagreen')\n",
    "        ax3.set_title(titles[2])\n",
    "\n",
    "        ax3.set_xlabel('Distance from Midpoint [km]')\n",
    "    else:\n",
    "        # Subplot 4\n",
    "        ax4 = axs[1, 1]\n",
    "        ax4.plot(x, y, color='lightcoral', alpha = .4, zorder = 1)\n",
    "        ax4.set_ylabel('$\\Delta$SST', color='lightcoral')\n",
    "        ax4.tick_params(axis='y', labelcolor='lightcoral')\n",
    "        \n",
    "        ax4_twin = ax4.twinx()\n",
    "        ax4_twin.plot(x, f_norm, color='seagreen', alpha = .4, zorder = 2)\n",
    "        ax4_twin.set_ylabel('Fluorometry', color='seagreen')\n",
    "        ax4_twin.tick_params(axis='y', labelcolor='seagreen')\n",
    "        ax4.set_title(titles[3])\n",
    "\n",
    "        ax4.set_xlabel('Distance from Midpoint [km]')\n",
    "\n",
    "# Common x-axis label\n",
    "# for ax in axs.flat:\n",
    "#     ax.label_outer()  # Only show outer labels\n",
    "\n",
    "# fig.text(0.5, 0.04, 'X-axis', ha='center')\n",
    "plt.tight_layout(rect=[0.04, 0.04, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce8b10-25d5-471e-a68a-74913202af91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f42ed158-a06e-4886-a791-eaa5317a040f",
   "metadata": {},
   "source": [
    "#### Geographic Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc4ee3-813c-4248-9530-10f365dbca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset, num2date\n",
    "\n",
    "fname = '/home/gstaller/Downloads/crm_socal_1as_vers2.nc'\n",
    "nc = Dataset(fname)\n",
    "\n",
    "res = 2\n",
    "\n",
    "lon, lat = np.array(nc.variables['lon'][::res]), np.array(nc.variables['lat'][::res])\n",
    "depths = np.array(nc.variables['Band1'][::res, ::res])\n",
    "\n",
    "lon_min = np.where((lon <= -118.25) & (lon > -118.85))[0][-1]\n",
    "lon_max = np.where((lon <= -118.25) & (lon > -118.85))[0][0]\n",
    "lat_min = np.where((lat >= 33.5) & (lat < 34.15))[0][0]\n",
    "lat_max = np.where((lat >= 33.5) & (lat < 34.15))[0][-1]\n",
    "\n",
    "depths = depths[lat_min:lat_max, lon_max:lon_min]\n",
    "\n",
    "lon    = lon[lon_max:lon_min]\n",
    "lat    = lat[lat_min:lat_max]\n",
    "\n",
    "# lat = lat[(lat >= lat_min) & (lat < lat_max)]\n",
    "# lon = lon[(lon > lon_max) & (lon <= lon_min)]\n",
    "\n",
    "lon, lat = np.meshgrid(lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a457714-eed0-4d6c-8148-bb9047c06e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_pos_fig = plt.figure(1, (20,15))\n",
    "showtracks = False\n",
    "\n",
    "long_lat_coords = [-118.85, -118.25, 33.7, 34.05]\n",
    "ax = plt.axes(projection = ccrs.PlateCarree())\n",
    "ax.set_extent(long_lat_coords)\n",
    "ax.coastlines()\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "plt.scatter(lon, lat, c = -1*depths, cmap = 'Blues', norm=matplotlib.colors.LogNorm(vmin=10, vmax=800))\n",
    "#plt.scatter(lon, lat, c = -1*depths, cmap = 'Blues', vmin = 10, vmax = 400)\n",
    " \n",
    "plt.colorbar(shrink = .6).set_label('Depth [m]', fontsize = 18)\n",
    "\n",
    "cs = plt.contour(lon, lat, depths, [-800, -600, -400, -200, -100, -50, -25, -10], cmap='Wistia_r', vmin=-10, alpha = .8)\n",
    "plt.clabel(cs, inline = True, fontsize = 14)\n",
    "\n",
    "for i in range(len(filament_ensemble)):\n",
    "    if showtracks == True:\n",
    "        x = filament_ensemble[str(i+1)]['Longitude']\n",
    "        y = filament_ensemble[str(i+1)]['Latitude']\n",
    "        z = filament_ensemble[str(i+1)]['SST']\n",
    "        plt.scatter(x, y, c = z, s = 1, cmap = 'jet')\n",
    "    else:\n",
    "        x = filament_ensemble[str(i+1)]['Min-Lon']\n",
    "        y = filament_ensemble[str(i+1)]['Min-Lat']\n",
    "        qx = filament_ensemble[str(i+1)]['x-comp']\n",
    "        qy = filament_ensemble[str(i+1)]['y-comp']\n",
    "        sym = filament_ensemble[str(i+1)]['Symmetry']\n",
    "        if sym < .5:\n",
    "            plt.quiver(x, y, qx, qy, width = .003, headwidth = .001, color = 'red', pivot = 'middle', zorder = 8)\n",
    "        elif (sym >= .5) and (sym < .7):     \n",
    "            plt.quiver(x, y, qx, qy, width = .003, headwidth = .001, color = 'yellow', pivot = 'middle', zorder = 9)\n",
    "        else:\n",
    "            plt.quiver(x, y, qx, qy, width = .003, headwidth = .001, color = 'green', pivot = 'middle', zorder = 10)\n",
    "        plt.plot(x, y, 'ko', markersize = 2, zorder = 11)\n",
    "\n",
    "\n",
    "plt.xticks(np.linspace(-118.80, -118.30, 5), fontsize=14)\n",
    "plt.yticks(np.arange(33.75, 34.05, .05), fontsize=14)\n",
    "#plt.yticks(np.linspace(33.7, 34.0, 5), fontsize=14)\n",
    "\n",
    "green_patch = mpatches.Patch(color='green', label='$\\Delta_{sym}$ $\\geq$ .7') \n",
    "orange_patch = mpatches.Patch(color='yellow', label='.5 $\\leq$ $\\Delta_{sym}$ < .7')\n",
    "red_patch = mpatches.Patch(color='red', label='.3 $\\leq$ $\\Delta_{sym}$ < .5')\n",
    "#black_patch = mpatches.Circle(color='black', label='Minimum SST')\n",
    "plt.legend(handles=[green_patch, orange_patch, red_patch], loc='upper right', fontsize = 18)\n",
    "        \n",
    "plt.title('Orientation and Position of Filaments', fontsize=fs_title)\n",
    "plt.xlabel('Longitude', fontsize = fs_label)\n",
    "plt.ylabel('Latitude', fontsize = fs_label)\n",
    "\n",
    "plt.savefig('fil_orientarion.png')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05565448-757c-451f-8ab2-a66e97afad4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
